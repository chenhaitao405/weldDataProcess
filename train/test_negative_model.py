import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib import rcParams
# è®¾ç½®matplotlibæ”¯æŒä¸­æ–‡
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False
from pathlib import Path
import json
from datetime import datetime
import platform

def imread_universal(file_path, flags=cv2.IMREAD_COLOR):
    """è·¨å¹³å°è¯»å–å›¾ç‰‡å‡½æ•°ï¼Œæ”¯æŒä¸åŒçš„è¯»å–æ¨¡å¼"""
    if platform.system() == "Windows":
        # Windowsä¸‹ä½¿ç”¨numpy+imdecodeæ–¹å¼
        with open(file_path, 'rb') as f:
            img_data = f.read()
        img_array = np.frombuffer(img_data, np.uint8)
        return cv2.imdecode(img_array, flags)
    else:
        # Linux/Macä¸‹ç›´æ¥ä½¿ç”¨cv2.imread
        return cv2.imread(file_path, flags)

class NegativeTransform:
    """è´Ÿç‰‡é¢„å¤„ç†ç±» - ä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´"""
    
    def __init__(self, apply_probability=1.0):
        """
        åˆå§‹åŒ–è´Ÿç‰‡å˜æ¢
        Args:
            apply_probability: åº”ç”¨è´Ÿç‰‡å˜æ¢çš„æ¦‚ç‡ (0-1ä¹‹é—´)
        """
        self.apply_probability = apply_probability
    
    def apply_negative(self, image):
        """
        å¯¹å›¾åƒåº”ç”¨è´Ÿç‰‡å˜æ¢
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C) RGBæ ¼å¼ï¼Œæ•°å€¼èŒƒå›´0-255
        Returns:
            è´Ÿç‰‡å˜æ¢åçš„å›¾åƒ
        """
        # è´Ÿç‰‡å˜æ¢å…¬å¼: output = 255 - input
        negative_image = 255 - image
        return negative_image.astype(np.uint8)
    
    def __call__(self, image, mask=None):
        """
        Albumentationså…¼å®¹çš„è°ƒç”¨æ–¹å¼
        """
        # æ ¹æ®æ¦‚ç‡å†³å®šæ˜¯å¦åº”ç”¨è´Ÿç‰‡å˜æ¢
        if np.random.random() < self.apply_probability:
            image_negative = self.apply_negative(image)
        else:
            image_negative = image
        
        if mask is not None:
            return {"image": image_negative, "mask": mask}
        else:
            return {"image": image_negative}

class WeldSegmentationModel:
    
    def __init__(self, num_classes=2, encoder_name='resnet50', use_negative=True):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.use_negative = use_negative
        
        # åˆå§‹åŒ–è´Ÿç‰‡å¤„ç†å™¨ - ä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´
        if use_negative:
            self.negative_processor = NegativeTransform(apply_probability=1.0)
            print("âœ… è´Ÿç‰‡é¢„å¤„ç†å·²å¯ç”¨ (apply_probability=1.0)")
        
        # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨ä¸è®­ç»ƒè„šæœ¬ä¸€è‡´çš„ResNet50
        self.model = smp.Unet(
            encoder_name=encoder_name,
            encoder_weights=None,  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå› ä¸ºè¦åŠ è½½è‡ªå·±çš„æ¨¡å‹
            in_channels=3,
            classes=num_classes,
        ).to(self.device)
        
        print(f"æ¨¡å‹å·²åˆ›å»ºï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ç¼–ç å™¨: {encoder_name}")
        print(f"è´Ÿç‰‡é¢„å¤„ç†: {'å¯ç”¨' if use_negative else 'ç¦ç”¨'}")
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_path):
            print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨")
            return False
            
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_path}")
        print(f"   æœ€ä½³Dice: {checkpoint.get('best_dice', 'N/A'):.4f}")
        if 'best_iou' in checkpoint:
            print(f"   æœ€ä½³IoU: {checkpoint['best_iou']:.4f}")
        return True
    
    def predict_single_image(self, image_path, transform):
        """é¢„æµ‹å•å¼ å›¾ç‰‡ï¼ˆåŒ…å«è´Ÿç‰‡é¢„å¤„ç†ï¼‰"""
        # è¯»å–å›¾ç‰‡
        image = imread_universal(str(image_path))
        if image is None:
            return None, None, None
            
        original_size = (image.shape[1], image.shape[0])  # (width, height)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # åº”ç”¨è´Ÿç‰‡é¢„å¤„ç† - ä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´
        image_enhanced = image_rgb.copy()
        if self.use_negative:
            processed = self.negative_processor(image_rgb)
            image_enhanced = processed['image']
        
        # å…¶ä»–é¢„å¤„ç†
        transformed = transform(image=image_enhanced)
        input_tensor = transformed['image'].unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            output = self.model(input_tensor)
            pred = torch.softmax(output, dim=1)
            pred_mask = torch.argmax(pred, dim=1).cpu().numpy()[0]
            confidence = torch.max(pred, dim=1)[0].cpu().numpy()[0]
        
        # æ¢å¤åŸå§‹å°ºå¯¸
        if pred_mask.shape != original_size[::-1]:  # (height, width)
            pred_mask = cv2.resize(pred_mask.astype(np.uint8), original_size, interpolation=cv2.INTER_NEAREST)
            confidence = cv2.resize(confidence, original_size, interpolation=cv2.INTER_LINEAR)
        
        return pred_mask, confidence, image_enhanced

def check_weld_detection(pred_mask, min_weld_pixels=500):
    """
    æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ç„Šç¼
    Args:
        pred_mask: é¢„æµ‹æ©ç 
        min_weld_pixels: æœ€å°ç„Šç¼åƒç´ æ•°é˜ˆå€¼
    Returns:
        bool: Trueè¡¨ç¤ºæ£€æµ‹åˆ°ç„Šç¼ï¼ŒFalseè¡¨ç¤ºæœªæ£€æµ‹åˆ°
    """
    weld_pixels = np.sum(pred_mask == 1)
    return weld_pixels >= min_weld_pixels

def save_no_weld_images(no_weld_images, output_dir, prefix=""):
    """
    ä¿å­˜æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡åç§°åˆ°æ–‡æœ¬æ–‡ä»¶
    Args:
        no_weld_images: æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡åç§°åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        prefix: æ–‡ä»¶åå‰ç¼€
    """
    if not no_weld_images:
        print("ğŸ“‹ æ‰€æœ‰å›¾ç‰‡éƒ½æ£€æµ‹åˆ°äº†ç„Šç¼")
        return None
    
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}no_weld_detected_{timestamp}.txt"
    file_path = output_dir / filename
    
    # ä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(f"æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡åˆ—è¡¨\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ€»è®¡: {len(no_weld_images)} å¼ å›¾ç‰‡\n")
        f.write("=" * 50 + "\n\n")
        
        for i, img_name in enumerate(no_weld_images, 1):
            f.write(f"{i:3d}. {img_name}\n")
    
    print(f"ğŸ“ æœªæ£€æµ‹ç„Šç¼å›¾ç‰‡åˆ—è¡¨å·²ä¿å­˜: {file_path}")
    print(f"ğŸ“Š æ€»è®¡ {len(no_weld_images)} å¼ å›¾ç‰‡æœªæ£€æµ‹åˆ°ç„Šç¼")
    
    return file_path

def get_rotated_bounding_box(pred_mask, image_to_draw_on, scale_factor=1.2):
    mask_uint8 = pred_mask.astype(np.uint8)
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        return image_to_draw_on, []

    all_rects = []

    for contour in contours:
        if cv2.contourArea(contour) < 500:
            continue

        # 1. è·å–åŸå§‹æ—‹è½¬çŸ©å½¢ä¿¡æ¯
        rect = cv2.minAreaRect(contour)
        
        # 2. æå–ä¿¡æ¯å¹¶åˆ›å»ºæ–°çš„ã€æ‰©å¤§åçš„çŸ©å½¢
        center, size, angle = rect
        new_size = (size[0] * scale_factor, size[1] * scale_factor)
        
        # åˆ›å»ºæ–°çš„æ—‹è½¬çŸ©å½¢å¯¹è±¡
        new_rect = (center, new_size, angle)
        all_rects.append(new_rect)
        
        # 3. è·å–æ–°çŸ©å½¢çš„å››ä¸ªé¡¶ç‚¹åæ ‡å¹¶ç»˜åˆ¶
        box = cv2.boxPoints(new_rect)
        box = np.intp(box)
        cv2.drawContours(image_to_draw_on, [box], 0, (0, 0, 255), 10)

    print(f"æ‰¾åˆ°å¹¶ç»˜åˆ¶äº† {len(all_rects)} ä¸ªæ‰©å¤§åçš„æ—‹è½¬çŸ©å½¢åŒºåŸŸã€‚")
    return image_to_draw_on, all_rects

def get_bounding_box_from_mask(pred_mask, image_to_draw_on, scale_factor=1.2):
    mask_uint8 = pred_mask.astype(np.uint8)
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        print("åœ¨æ©ç ä¸­æœªæ‰¾åˆ°ä»»ä½•è½®å»“ã€‚")
        return image_to_draw_on, []

    all_boxes = []

    for contour in contours:
        if cv2.contourArea(contour) < 500:
            continue

        # 1. è·å–åŸå§‹çŸ©å½¢
        x, y, w, h = cv2.boundingRect(contour)

        # 2. è®¡ç®—æ–°çš„å®½åº¦å’Œé«˜åº¦
        new_w = int(w * scale_factor)
        new_h = int(h * scale_factor)

        # 3. è®¡ç®—æ–°çš„å·¦ä¸Šè§’åæ ‡ï¼Œä»¥ä¿æŒä¸­å¿ƒç‚¹ä¸å˜
        new_x = int(x - (new_w - w) / 2)
        new_y = int(y - (new_h - h) / 2)

        # 4. å°†æ–°åæ ‡å­˜å…¥åˆ—è¡¨
        all_boxes.append((new_x, new_y, new_w, new_h))

        # 5. åœ¨å›¾åƒä¸Šç»˜åˆ¶æ‰©å¤§åçš„æ–°çŸ©å½¢
        cv2.rectangle(image_to_draw_on, (new_x, new_y), (new_x + new_w, new_y + new_h), (0, 255, 0), 10)
    
    print(f"æ‰¾åˆ°å¹¶ç»˜åˆ¶äº† {len(all_boxes)} ä¸ªæ‰©å¤§åçš„æœ‰æ•ˆçŸ©å½¢åŒºåŸŸã€‚")
    return image_to_draw_on, all_boxes

def get_test_transform():
    """è·å–æµ‹è¯•æ—¶çš„å˜æ¢ - ä¸è®­ç»ƒè„šæœ¬ä¿æŒä¸€è‡´"""
    return A.Compose([
        A.Resize(512, 512),  # ä½¿ç”¨ä¸è®­ç»ƒä¸€è‡´çš„512x512åˆ†è¾¨ç‡
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

def visualize_prediction(image_path, pred_mask, confidence, enhanced_image, output_dir, use_negative=True):
    """å¯è§†åŒ–å•ä¸ªé¢„æµ‹ç»“æœï¼ˆåŒ…å«è´Ÿç‰‡å¯¹æ¯”ï¼‰"""
    # è¯»å–åŸå›¾
    image = imread_universal(str(image_path))
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    image_to_draw_on, rect = get_rotated_bounding_box(pred_mask, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    image_to_draw_on1, rect1 = get_bounding_box_from_mask(pred_mask, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # åˆ›å»ºå åŠ å›¾
    overlay = enhanced_image.copy()
    
    # ç„Šç¼åŒºåŸŸç”¨çº¢è‰²æ ‡å‡º
    weld_mask = (pred_mask == 1)
    overlay[weld_mask] = overlay[weld_mask] * 0.6 + np.array([255, 0, 0]) * 0.4
    
    # ç»˜åˆ¶è¾¹ç•Œ
    contours, _ = cv2.findContours(weld_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    overlay_bgr = cv2.cvtColor(overlay.astype(np.uint8), cv2.COLOR_RGB2BGR)
    cv2.drawContours(overlay_bgr, contours, -1, (0, 255, 0), 2)
    overlay = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_pixels = pred_mask.shape[0] * pred_mask.shape[1]
    weld_pixels = np.sum(weld_mask)
    weld_ratio = weld_pixels / total_pixels * 100
    avg_confidence = np.mean(confidence[weld_mask]) if weld_pixels > 0 else 0
    
    # åˆ›å»ºå¯è§†åŒ–ï¼ˆåŒ…å«è´Ÿç‰‡å¯¹æ¯”ï¼‰
    if use_negative:
        fig, axes = plt.subplots(3, 3, figsize=(18, 12))
        
        # ç¬¬ä¸€è¡Œï¼šåŸå›¾ã€è´Ÿç‰‡å¢å¼ºã€é¢„æµ‹æ©ç 
        axes[0, 0].imshow(image_rgb)
        axes[0, 0].set_title('åŸå§‹å›¾ç‰‡', fontsize=12)
        axes[0, 0].axis('off')
        
        axes[0, 1].imshow(enhanced_image)
        axes[0, 1].set_title('è´Ÿç‰‡å˜æ¢å (255 - input)', fontsize=12)
        axes[0, 1].axis('off')
        
        axes[0, 2].imshow(pred_mask, cmap='gray')
        axes[0, 2].set_title('é¢„æµ‹æ©ç ', fontsize=12)
        axes[0, 2].axis('off')
        
        # ç¬¬äºŒè¡Œï¼šå åŠ ç»“æœã€ç½®ä¿¡åº¦å›¾ã€å¯¹æ¯”å›¾
        axes[1, 0].imshow(overlay)
        axes[1, 0].set_title('æ£€æµ‹ç»“æœå åŠ ', fontsize=12)
        axes[1, 0].axis('off')
        
        im = axes[1, 1].imshow(confidence, cmap='jet', vmin=0, vmax=1)
        axes[1, 1].set_title('ç½®ä¿¡åº¦å›¾', fontsize=12)
        axes[1, 1].axis('off')
        plt.colorbar(im, ax=axes[1, 1], fraction=0.046, pad=0.04)
        
        # è´Ÿç‰‡å‰åå¯¹æ¯”
        comparison = np.hstack([image_rgb[:, :image_rgb.shape[1]//2], 
                               enhanced_image[:, enhanced_image.shape[1]//2:]])
        axes[1, 2].imshow(comparison)
        axes[1, 2].set_title('è´Ÿç‰‡å‰åå¯¹æ¯”\n(å·¦:åŸå›¾ å³:è´Ÿç‰‡)', fontsize=12)
        axes[1, 2].axis('off')

        # ç¬¬ä¸‰è¡Œï¼šè¾¹ç•Œæ¡†æ£€æµ‹ç»“æœ
        axes[2, 0].imshow(image_to_draw_on)
        axes[2, 0].set_title('æ—‹è½¬è¾¹ç•Œæ¡†æ£€æµ‹', fontsize=12)
        axes[2, 0].axis('off')

        axes[2, 1].imshow(image_to_draw_on1)
        axes[2, 1].set_title('æ™®é€šè¾¹ç•Œæ¡†æ£€æµ‹', fontsize=12)
        axes[2, 1].axis('off')
        
        # ç©ºç™½ä½ç½®æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        axes[2, 2].axis('off')
        stats_text = f'ç„Šç¼åƒç´ : {weld_pixels:,}\næ€»åƒç´ : {total_pixels:,}\nç„Šç¼å æ¯”: {weld_ratio:.2f}%\nå¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}'
        axes[2, 2].text(0.1, 0.5, stats_text, fontsize=14, transform=axes[2, 2].transAxes, 
                        verticalalignment='center', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"))
        
    else:
        # ä¸ä½¿ç”¨è´Ÿç‰‡æ—¶çš„ç®€åŒ–ç‰ˆæœ¬
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        axes[0, 0].imshow(image_rgb)
        axes[0, 0].set_title('åŸå§‹å›¾ç‰‡', fontsize=12)
        axes[0, 0].axis('off')
        
        axes[0, 1].imshow(pred_mask, cmap='gray')
        axes[0, 1].set_title('é¢„æµ‹æ©ç ', fontsize=12)
        axes[0, 1].axis('off')
        
        axes[1, 0].imshow(overlay)
        axes[1, 0].set_title('å åŠ ç»“æœ', fontsize=12)
        axes[1, 0].axis('off')
        
        im = axes[1, 1].imshow(confidence, cmap='jet', vmin=0, vmax=1)
        axes[1, 1].set_title('ç½®ä¿¡åº¦å›¾', fontsize=12)
        axes[1, 1].axis('off')
        plt.colorbar(im, ax=axes[1, 1], fraction=0.046, pad=0.04)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    negative_info = " (è´Ÿç‰‡å¢å¼º)" if use_negative else ""
    info_text = f'ç„Šç¼åƒç´ : {weld_pixels:,}\næ€»åƒç´ : {total_pixels:,}\nç„Šç¼å æ¯”: {weld_ratio:.2f}%\nå¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}'
    fig.suptitle(f'{Path(image_path).name}{negative_info}\n{info_text}', fontsize=11)
    
    plt.tight_layout()
    
    # ä¿å­˜ç»“æœ
    output_path = output_dir / f'result_{Path(image_path).stem}.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    return {
        'weld_pixels': int(weld_pixels),
        'total_pixels': int(total_pixels),
        'weld_ratio': float(weld_ratio),
        'avg_confidence': float(avg_confidence),
        'num_contours': len(contours),
        'has_weld': weld_pixels >= 500  # æ·»åŠ ç„Šç¼æ£€æµ‹æ ‡å¿—
    }

def save_negative_comparison(original_image, enhanced_image, image_name, output_dir):
    """ä¿å­˜è´Ÿç‰‡å‰åå¯¹æ¯”å›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    ax1.imshow(original_image)
    ax1.set_title('åŸå§‹å›¾åƒ')
    ax1.axis('off')
    
    ax2.imshow(enhanced_image)
    ax2.set_title('è´Ÿç‰‡å˜æ¢å (255 - input)')
    ax2.axis('off')
    
    plt.tight_layout()
    
    comparison_path = output_dir / f'negative_comparison_{Path(image_name).stem}.png'
    plt.savefig(comparison_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    return comparison_path

def test_on_images(model, image_dir, output_dir, max_images=None, min_weld_pixels=500):
    """æµ‹è¯•æ¨¡å‹åœ¨å›¾ç‰‡ç›®å½•ä¸Šçš„è¡¨ç°ï¼ˆæ”¯æŒè´Ÿç‰‡é¢„å¤„ç†å’Œæœªæ£€æµ‹è®°å½•ï¼‰"""
    image_dir = Path(image_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•
    (output_dir / 'predictions').mkdir(exist_ok=True)
    if model.use_negative:
        (output_dir / 'negative_comparisons').mkdir(exist_ok=True)
    
    # è·å–æ‰€æœ‰å›¾ç‰‡
    image_extensions = ['.bmp', '.jpg', '.jpeg', '.png', '.tif']
    all_images = []
    for ext in image_extensions:
        all_images.extend(list(image_dir.glob(f'*{ext}')))
    
    if max_images:
        all_images = all_images[:max_images]
    
    if not all_images:
        print(f"åœ¨ {image_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ° {len(all_images)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹é¢„æµ‹...")
    print(f"è´Ÿç‰‡é¢„å¤„ç†: {'å¯ç”¨' if model.use_negative else 'ç¦ç”¨'}")
    print(f"æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼: {min_weld_pixels}")
    
    transform = get_test_transform()
    results = []
    no_weld_images = []  # å­˜å‚¨æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡åç§°
    
    for i, img_path in enumerate(all_images):
        print(f"å¤„ç† {i+1}/{len(all_images)}: {img_path.name}")
        
        # é¢„æµ‹
        pred_result = model.predict_single_image(img_path, transform)
        if pred_result[0] is None:
            print(f"  è·³è¿‡ï¼ˆæ— æ³•è¯»å–å›¾ç‰‡ï¼‰")
            continue
        
        pred_mask, confidence, enhanced_image = pred_result
        
        # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ç„Šç¼
        has_weld = check_weld_detection(pred_mask, min_weld_pixels)
        if not has_weld:
            no_weld_images.append(img_path.name)
            print(f"  âš ï¸ æœªæ£€æµ‹åˆ°ç„Šç¼ï¼ˆåƒç´ æ•°: {np.sum(pred_mask == 1)}ï¼‰")
        
        # å¯è§†åŒ–å’Œç»Ÿè®¡
        stats = visualize_prediction(
            img_path, pred_mask, confidence, enhanced_image, 
            output_dir / 'predictions', model.use_negative
        )
        stats['image_name'] = img_path.name
        stats['has_weld'] = has_weld
        results.append(stats)
        
        # ä¿å­˜è´Ÿç‰‡å¯¹æ¯”å›¾ï¼ˆå‰5å¼ ä½œä¸ºç¤ºä¾‹ï¼‰
        if model.use_negative and i < 5:
            original_image = cv2.cvtColor(imread_universal(str(img_path)), cv2.COLOR_BGR2RGB)
            save_negative_comparison(
                original_image, enhanced_image, img_path.name, 
                output_dir / 'negative_comparisons'
            )
        
        print(f"  ç„Šç¼å æ¯”: {stats['weld_ratio']:.2f}%, ç½®ä¿¡åº¦: {stats['avg_confidence']:.3f}")
    
    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    save_test_report(results, output_dir, model.use_negative)
    
    # ä¿å­˜æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡åˆ—è¡¨
    no_weld_file = save_no_weld_images(no_weld_images, output_dir, 
                                       "negative_" if model.use_negative else "")
    
    # æ‰“å°æ€»ç»“
    total_tested = len(results)
    no_weld_count = len(no_weld_images)
    detection_rate = (total_tested - no_weld_count) / total_tested * 100 if total_tested > 0 else 0
    
    print(f"\nğŸ“Š æ£€æµ‹æ€»ç»“:")
    print(f"  æ€»æµ‹è¯•å›¾ç‰‡: {total_tested}")
    print(f"  æ£€æµ‹åˆ°ç„Šç¼: {total_tested - no_weld_count}")
    print(f"  æœªæ£€æµ‹åˆ°ç„Šç¼: {no_weld_count}")
    print(f"  æ£€æµ‹æˆåŠŸç‡: {detection_rate:.1f}%")
    
    return results

def save_test_report(results, output_dir, use_negative=True):
    """ä¿å­˜æµ‹è¯•æŠ¥å‘Šï¼ˆåŒ…å«è´Ÿç‰‡ä¿¡æ¯å’Œæœªæ£€æµ‹ç»Ÿè®¡ï¼‰"""
    if not results:
        return
    
    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    total_images = len(results)
    weld_ratios = [r['weld_ratio'] for r in results]
    confidences = [r['avg_confidence'] for r in results if r['avg_confidence'] > 0]
    
    # ç»Ÿè®¡æ£€æµ‹æƒ…å†µ
    detected_count = sum(1 for r in results if r.get('has_weld', True))
    not_detected_count = total_images - detected_count
    detection_rate = detected_count / total_images * 100 if total_images > 0 else 0
    
    report = {
        'test_time': datetime.now().isoformat(),
        'total_images': total_images,
        'detected_images': detected_count,
        'not_detected_images': not_detected_count,
        'detection_rate': detection_rate,
        'negative_enabled': use_negative,
        'negative_params': {
            'formula': '255 - input',
            'apply_probability': 1.0
        } if use_negative else None,
        'statistics': {
            'weld_ratio': {
                'mean': float(np.mean(weld_ratios)),
                'std': float(np.std(weld_ratios)),
                'min': float(np.min(weld_ratios)),
                'max': float(np.max(weld_ratios))
            },
            'confidence': {
                'mean': float(np.mean(confidences)) if confidences else 0,
                'std': float(np.std(confidences)) if confidences else 0,
                'min': float(np.min(confidences)) if confidences else 0,
                'max': float(np.max(confidences)) if confidences else 0
            }
        },
        'details': results
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    report_path = output_dir / 'test_report.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
    txt_report_path = output_dir / 'test_report.txt'
    with open(txt_report_path, 'w', encoding='utf-8') as f:
        f.write("ç„Šç¼æ£€æµ‹æµ‹è¯•æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {report['test_time']}\n")
        f.write(f"æµ‹è¯•å›¾ç‰‡æ•°: {total_images}\n")
        f.write(f"æ£€æµ‹åˆ°ç„Šç¼: {detected_count}\n")
        f.write(f"æœªæ£€æµ‹åˆ°ç„Šç¼: {not_detected_count}\n")
        f.write(f"æ£€æµ‹æˆåŠŸç‡: {detection_rate:.1f}%\n")
        f.write(f"è´Ÿç‰‡é¢„å¤„ç†: {'å¯ç”¨' if use_negative else 'ç¦ç”¨'}\n")
        if use_negative:
            f.write(f"è´Ÿç‰‡å…¬å¼: output = 255 - input\n")
        f.write("\n")
        
        f.write("ç„Šç¼å æ¯”ç»Ÿè®¡:\n")
        f.write(f"  å¹³å‡å€¼: {report['statistics']['weld_ratio']['mean']:.2f}%\n")
        f.write(f"  æ ‡å‡†å·®: {report['statistics']['weld_ratio']['std']:.2f}%\n")
        f.write(f"  æœ€å°å€¼: {report['statistics']['weld_ratio']['min']:.2f}%\n")
        f.write(f"  æœ€å¤§å€¼: {report['statistics']['weld_ratio']['max']:.2f}%\n\n")
        
        f.write("é¢„æµ‹ç½®ä¿¡åº¦ç»Ÿè®¡:\n")
        f.write(f"  å¹³å‡å€¼: {report['statistics']['confidence']['mean']:.3f}\n")
        f.write(f"  æ ‡å‡†å·®: {report['statistics']['confidence']['std']:.3f}\n")
        f.write(f"  æœ€å°å€¼: {report['statistics']['confidence']['min']:.3f}\n")
        f.write(f"  æœ€å¤§å€¼: {report['statistics']['confidence']['max']:.3f}\n\n")
        
        f.write("è¯¦ç»†ç»“æœ:\n")
        for result in results:
            weld_status = "âœ“" if result.get('has_weld', True) else "âœ—"
            f.write(f"{weld_status} {result['image_name']}: ")
            f.write(f"ç„Šç¼{result['weld_ratio']:.2f}%, ")
            f.write(f"ç½®ä¿¡åº¦{result['avg_confidence']:.3f}\n")
    
    print(f"\nğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜:")
    print(f"  è¯¦ç»†æŠ¥å‘Š: {report_path}")
    print(f"  æ–‡æœ¬æŠ¥å‘Š: {txt_report_path}")

def quick_filter_false_welds(pred_mask, confidence_map=None, image_height=None):
    """
    å¼ºåŒ–ç‰ˆå‡ç„Šç¼è¿‡æ»¤ - ä¸“é—¨é’ˆå¯¹ä¸Šæ–¹æ–‡å­—/æ ‡è®°è¯¯è¯†åˆ«é—®é¢˜
    """
    if image_height is None:
        image_height = pred_mask.shape[0]
    
    image_width = pred_mask.shape[1]
    filtered_mask = np.zeros_like(pred_mask)
    
    # æ‰¾åˆ°æ‰€æœ‰è¿é€šåŒºåŸŸ
    weld_mask = (pred_mask == 1).astype(np.uint8)
    contours, _ = cv2.findContours(weld_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    print(f"å‘ç° {len(contours)} ä¸ªç„Šç¼åŒºåŸŸï¼Œå¼€å§‹å¼ºåŒ–è¿‡æ»¤...")
    
    valid_contours = []
    
    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        
        # åŸºæœ¬é¢ç§¯è¿‡æ»¤
        if area < 500:
            print(f"  åŒºåŸŸ{i+1}: é¢ç§¯å¤ªå°({area:.0f}) - è¿‡æ»¤")
            continue
        
        # è®¡ç®—åŒºåŸŸå‡ ä½•ç‰¹å¾
        M = cv2.moments(contour)
        if M["m00"] == 0:
            continue
            
        cx = int(M["m10"] / M["m00"])  # è´¨å¿ƒxåæ ‡
        cy = int(M["m01"] / M["m00"])  # è´¨å¿ƒyåæ ‡
        
        # è®¡ç®—æœ€å°å¤–æ¥çŸ©å½¢
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        w, h = rect[1]
        
        if w == 0 or h == 0:
            continue
            
        aspect_ratio = max(w, h) / min(w, h)
        
        # è®¡ç®—åŒºåŸŸä½ç½®ï¼ˆåˆ†ä¸ºä¸Šä¸­ä¸‹ä¸‰éƒ¨åˆ†ï¼‰
        position = "ä¸‹éƒ¨" if cy > 2 * image_height / 3 else ("ä¸­éƒ¨" if cy > image_height / 3 else "ä¸Šéƒ¨")
        
        print(f"  åŒºåŸŸ{i+1}: {position} (x={cx}, y={cy}, é¢ç§¯={area:.0f}, é•¿å®½æ¯”={aspect_ratio:.2f})")
        
        # ä¸Šéƒ¨åŒºåŸŸï¼ˆæœ€ä¸¥æ ¼ï¼‰- è¿™é‡Œæ˜¯æ–‡å­—/æ ‡è®°æœ€å®¹æ˜“å‡ºç°çš„åœ°æ–¹
        if cy < image_height / 3:
            print(f"    ä½äºä¸Šéƒ¨åŒºåŸŸï¼Œåº”ç”¨ä¸¥æ ¼è¿‡æ»¤...")
            
            # 1. é¢ç§¯è¿‡æ»¤ï¼šä¸Šéƒ¨å°é¢ç§¯ç›´æ¥è¿‡æ»¤
            if area < 3000:  # æé«˜ä¸Šéƒ¨é¢ç§¯é˜ˆå€¼
                print(f"    ä¸Šéƒ¨é¢ç§¯è¿‡å°({area:.0f} < 3000) - è¿‡æ»¤")
                continue
            
            # 2. é•¿å®½æ¯”è¿‡æ»¤ï¼šä¸Šéƒ¨åŒºåŸŸå¿…é¡»æ˜¯æ˜æ˜¾çš„é•¿æ¡å½¢
            if aspect_ratio < 3.0:  # æé«˜é•¿å®½æ¯”è¦æ±‚
                print(f"    ä¸Šéƒ¨é•¿å®½æ¯”ä¸è¶³({aspect_ratio:.2f} < 3.0) - è¿‡æ»¤")
                continue
            
            # 3. ç½®ä¿¡åº¦è¿‡æ»¤ï¼šä¸Šéƒ¨éœ€è¦éå¸¸é«˜çš„ç½®ä¿¡åº¦
            if confidence_map is not None:
                mask_region = np.zeros_like(pred_mask)
                cv2.fillPoly(mask_region, [contour], 1)
                avg_confidence = np.mean(confidence_map[mask_region == 1])
                
                if avg_confidence < 0.85:  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼
                    print(f"    ä¸Šéƒ¨ç½®ä¿¡åº¦ä¸è¶³({avg_confidence:.3f} < 0.85) - è¿‡æ»¤")
                    continue
            
            # 4. å½¢çŠ¶ç‰¹å¾è¿‡æ»¤ï¼šæ£€æŸ¥æ˜¯å¦åƒæ–‡å­—
            # è®¡ç®—è½®å»“çš„å‡¸åŒ…
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area > 0 else 0
            
            # æ–‡å­—é€šå¸¸ä¸å¤Ÿ"å®å¿ƒ"
            if solidity < 0.7:
                print(f"    ä¸Šéƒ¨å®å¿ƒåº¦ä¸è¶³({solidity:.3f} < 0.7) - ç–‘ä¼¼æ–‡å­—ï¼Œè¿‡æ»¤")
                continue
            
            # 5. ä½ç½®åˆç†æ€§æ£€æŸ¥ï¼šçœŸæ­£çš„ç„Šç¼é€šå¸¸åœ¨ç®¡é“è¿æ¥å¤„
            # æ£€æŸ¥æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘ï¼ˆæ–‡å­—é€šå¸¸åœ¨ä¸­é—´ï¼‰
            edge_distance = min(cx, image_width - cx, cy, image_height - cy)
            relative_edge_distance = edge_distance / min(image_width, image_height)
            
            if relative_edge_distance > 0.3:  # è·ç¦»è¾¹ç¼˜å¤ªè¿œ
                print(f"    è·ç¦»è¾¹ç¼˜å¤ªè¿œ({relative_edge_distance:.3f}) - ç–‘ä¼¼æ–‡å­—ï¼Œè¿‡æ»¤")
                continue
                
        # ä¸­éƒ¨åŒºåŸŸï¼ˆä¸­ç­‰ä¸¥æ ¼ï¼‰
        elif cy < 2 * image_height / 3:
            print(f"    ä½äºä¸­éƒ¨åŒºåŸŸï¼Œåº”ç”¨ä¸­ç­‰è¿‡æ»¤...")
            
            if area < 1500:
                print(f"    ä¸­éƒ¨é¢ç§¯è¿‡å°({area:.0f} < 1500) - è¿‡æ»¤")
                continue
                
            # æ”¾å®½ä¸­éƒ¨åŒºåŸŸçš„é•¿å®½æ¯”è¦æ±‚
            if aspect_ratio < 1.8:  # ä»2.0é™ä½åˆ°1.8
                print(f"    ä¸­éƒ¨é•¿å®½æ¯”ä¸è¶³({aspect_ratio:.2f} < 1.8) - è¿‡æ»¤")
                continue
                
            if confidence_map is not None:
                mask_region = np.zeros_like(pred_mask)
                cv2.fillPoly(mask_region, [contour], 1)
                avg_confidence = np.mean(confidence_map[mask_region == 1])
                
                if avg_confidence < 0.6:  # ä»0.65é™ä½åˆ°0.6
                    print(f"    ä¸­éƒ¨ç½®ä¿¡åº¦ä¸è¶³({avg_confidence:.3f} < 0.6) - è¿‡æ»¤")
                    continue
        
        # ä¸‹éƒ¨åŒºåŸŸï¼ˆç›¸å¯¹å®½æ¾ï¼‰- çœŸæ­£çš„ç„Šç¼å¤šåœ¨è¿™é‡Œ
        else:
            print(f"    ä½äºä¸‹éƒ¨åŒºåŸŸï¼Œåº”ç”¨å®½æ¾è¿‡æ»¤...")
            
            if area < 800:
                print(f"    ä¸‹éƒ¨é¢ç§¯è¿‡å°({area:.0f} < 800) - è¿‡æ»¤")
                continue
                
            if aspect_ratio < 1.5:
                print(f"    ä¸‹éƒ¨é•¿å®½æ¯”ä¸è¶³({aspect_ratio:.2f} < 1.5) - è¿‡æ»¤")
                continue
        
        # é€šè¿‡æ‰€æœ‰æ¡ä»¶çš„åŒºåŸŸ
        print(f"    âœ… åŒºåŸŸ{i+1}é€šè¿‡è¿‡æ»¤")
        valid_contours.append(contour)
    
    # ç»˜åˆ¶æœ‰æ•ˆåŒºåŸŸ
    for contour in valid_contours:
        cv2.fillPoly(filtered_mask, [contour], 1)
    
    print(f"è¿‡æ»¤ç»“æœ: {len(contours)} -> {len(valid_contours)} ä¸ªåŒºåŸŸ")
    return filtered_mask

def visualize_filter_comparison(image_path, original_mask, filtered_mask, confidence, enhanced_image):
    """å¯è§†åŒ–è¿‡æ»¤å‰åå¯¹æ¯”"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    orig_weld_pixels = np.sum(original_mask == 1)
    filt_weld_pixels = np.sum(filtered_mask == 1)
    total_pixels = original_mask.shape[0] * original_mask.shape[1]
    reduction_ratio = (orig_weld_pixels - filt_weld_pixels) / orig_weld_pixels if orig_weld_pixels > 0 else 0
    
    # åˆ›å»ºå åŠ å›¾
    def create_overlay(img, mask, color=[255, 0, 0]):
        overlay = img.copy()
        weld_mask = (mask == 1)
        if np.any(weld_mask):
            overlay[weld_mask] = overlay[weld_mask] * 0.6 + np.array(color) * 0.4
            # ç»˜åˆ¶è¾¹ç•Œ
            contours, _ = cv2.findContours(weld_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            overlay_bgr = cv2.cvtColor(overlay.astype(np.uint8), cv2.COLOR_RGB2BGR)
            cv2.drawContours(overlay_bgr, contours, -1, (0, 255, 0), 2)
            overlay = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2RGB)
        return overlay
    
    original_overlay = create_overlay(enhanced_image, original_mask, [255, 0, 0])  # çº¢è‰²
    filtered_overlay = create_overlay(enhanced_image, filtered_mask, [0, 255, 0])  # ç»¿è‰²
    
    # ç¬¬ä¸€è¡Œ
    axes[0, 0].imshow(enhanced_image)
    axes[0, 0].set_title('è´Ÿç‰‡å¢å¼ºå›¾', fontsize=12)
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(original_mask, cmap='gray')
    axes[0, 1].set_title(f'åŸå§‹é¢„æµ‹\nç„Šç¼å æ¯”: {orig_weld_pixels/total_pixels*100:.2f}%', fontsize=12)
    axes[0, 1].axis('off')
    
    axes[0, 2].imshow(filtered_mask, cmap='gray')
    axes[0, 2].set_title(f'è¿‡æ»¤åç»“æœ\nç„Šç¼å æ¯”: {filt_weld_pixels/total_pixels*100:.2f}%', fontsize=12)
    axes[0, 2].axis('off')
    
    # ç¬¬äºŒè¡Œ
    axes[1, 0].imshow(original_overlay)
    axes[1, 0].set_title('åŸå§‹é¢„æµ‹å åŠ ï¼ˆçº¢è‰²ï¼‰', fontsize=12)
    axes[1, 0].axis('off')
    
    axes[1, 1].imshow(filtered_overlay)
    axes[1, 1].set_title('è¿‡æ»¤åå åŠ ï¼ˆç»¿è‰²ï¼‰', fontsize=12)
    axes[1, 1].axis('off')
    
    # ç½®ä¿¡åº¦å›¾
    im = axes[1, 2].imshow(confidence, cmap='jet', vmin=0, vmax=1)
    axes[1, 2].set_title('ç½®ä¿¡åº¦å›¾', fontsize=12)
    axes[1, 2].axis('off')
    plt.colorbar(im, ax=axes[1, 2], fraction=0.046, pad=0.04)
    
    # æ€»æ ‡é¢˜
    fig.suptitle(f'{Path(image_path).name} - å‡ç„Šç¼è¿‡æ»¤å¯¹æ¯”\nå‡å°‘äº† {reduction_ratio*100:.1f}% çš„å‡é˜³æ€§', fontsize=14)
    plt.tight_layout()
    
    # ä¿å­˜å¯¹æ¯”å›¾
    output_path = Path('filter_comparison.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"è¿‡æ»¤å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ç„Šç¼æ£€æµ‹æ¨¡å‹æµ‹è¯•å·¥å…· - è´Ÿç‰‡é¢„å¤„ç†ç‰ˆæœ¬")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_paths = [
        'best_weld_model_negative_3080.pth',   # è´Ÿç‰‡ç‰ˆæœ¬ä¼˜å…ˆ
        # 'best_weld_model_negative.pth',
        # 'best_model_negative.pth',
        # 'best_weld_model_v2.pth',              # å¤‡é€‰
        # 'best_weld_model.pth'                  # é»˜è®¤åç§°
    ]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„æ˜¯å¦å­˜åœ¨:")
        for path in model_paths:
            print(f"  - {path}")
        return
    
    # è¯¢é—®æ˜¯å¦å¯ç”¨è´Ÿç‰‡é¢„å¤„ç†
    print(f"\næ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
    print("æ˜¯å¦å¯ç”¨è´Ÿç‰‡é¢„å¤„ç†ï¼Ÿ")
    print("  å»ºè®®ï¼šå¦‚æœæ¨¡å‹ä½¿ç”¨è´Ÿç‰‡è®­ç»ƒï¼Œæµ‹è¯•æ—¶ä¹Ÿåº”å¯ç”¨è´Ÿç‰‡é¢„å¤„ç†")
    use_negative_input = input("å¯ç”¨è´Ÿç‰‡é¢„å¤„ç†ï¼Ÿ(Y/n): ").strip().lower()
    use_negative = use_negative_input != 'n'
    
    # è®¾ç½®æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼
    min_weld_pixels_input = input("è®¾ç½®æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼ (é»˜è®¤500): ").strip()
    min_weld_pixels = int(min_weld_pixels_input) if min_weld_pixels_input.isdigit() else 500
    print(f"æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼: {min_weld_pixels}")
    
    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    # æ ¹æ®æ¨¡å‹æ–‡ä»¶åè‡ªåŠ¨é€‰æ‹©ç¼–ç å™¨
    encoder_name =  'resnet50'
    model = WeldSegmentationModel(encoder_name=encoder_name, use_negative=use_negative)
    if not model.load_model(model_path):
        return
    
    # é€‰æ‹©æµ‹è¯•æ–¹å¼
    print("\né€‰æ‹©æµ‹è¯•æ–¹å¼:")
    print("1. æµ‹è¯•å•å¼ å›¾ç‰‡")
    print("2. æµ‹è¯•testç›®å½•æ‰€æœ‰å›¾ç‰‡")
    print("3. æµ‹è¯•testç›®å½•å‰10å¼ å›¾ç‰‡ï¼ˆå¿«é€Ÿé¢„è§ˆï¼‰")
    print("4. æµ‹è¯•æŒ‡å®šç›®å½•")
    print("5. è´Ÿç‰‡æ•ˆæœå¯¹æ¯”æµ‹è¯•")
    print("6. å‡ç„Šç¼è¿‡æ»¤æ•ˆæœæµ‹è¯•ï¼ˆæ¨èï¼‰")
    print("7. å•å¼ å›¾ç‰‡è¿‡æ»¤æµ‹è¯•ï¼ˆæ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹ï¼‰")
    print("8. æ‰¹é‡æ£€æµ‹æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡ï¼ˆæ–°åŠŸèƒ½ï¼‰")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-8): ").strip()
    
    if choice == '1':
        # æµ‹è¯•å•å¼ å›¾ç‰‡
        img_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        # å¤„ç†è·¯å¾„ä¸­çš„å¼•å·
        img_path = img_path.strip("'\"")
        
        if not os.path.exists(img_path):
            print("å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨")
            return
        
        output_dir = Path('single_test_result_negative')
        output_dir.mkdir(exist_ok=True)
        
        transform = get_test_transform()
        pred_result = model.predict_single_image(img_path, transform)
        
        if pred_result[0] is not None:
            pred_mask, confidence, enhanced_image = pred_result
            has_weld = check_weld_detection(pred_mask, min_weld_pixels)
            
            stats = visualize_prediction(
                img_path, pred_mask, confidence, enhanced_image, 
                output_dir, use_negative
            )
            print(f"\né¢„æµ‹å®Œæˆ:")
            print(f"  ç„Šç¼æ£€æµ‹: {'âœ… æ£€æµ‹åˆ°' if has_weld else 'âŒ æœªæ£€æµ‹åˆ°'}")
            print(f"  ç„Šç¼å æ¯”: {stats['weld_ratio']:.2f}%")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.3f}")
            print(f"  è´Ÿç‰‡é¢„å¤„ç†: {'å¯ç”¨' if use_negative else 'ç¦ç”¨'}")
            print(f"  ç»“æœä¿å­˜åœ¨: {output_dir}")
            
            if not has_weld:
                no_weld_file = save_no_weld_images([Path(img_path).name], output_dir)
    
    elif choice == '2':
        # æµ‹è¯•testç›®å½•æ‰€æœ‰å›¾ç‰‡
        test_dir = 'æ ‡æ³¨/test'
        output_dir = f'test_results_full{"_negative" if use_negative else ""}'
        test_on_images(model, test_dir, output_dir, min_weld_pixels=min_weld_pixels)
        
    elif choice == '3':
        # æµ‹è¯•å‰10å¼ 
        test_dir = 'æ ‡æ³¨/test'
        output_dir = f'test_results_preview{"_negative" if use_negative else ""}'
        test_on_images(model, test_dir, output_dir, max_images=10, min_weld_pixels=min_weld_pixels)
        
    elif choice == '4':
        # æµ‹è¯•æŒ‡å®šç›®å½•
        test_dir = input("è¯·è¾“å…¥å›¾ç‰‡ç›®å½•è·¯å¾„: ").strip()
        if not os.path.exists(test_dir):
            print("ç›®å½•ä¸å­˜åœ¨:", test_dir)
            return
        output_dir = f'test_results_custom{"_negative" if use_negative else ""}'
        max_imgs = input("æœ€å¤§å›¾ç‰‡æ•°é‡ï¼ˆå›è½¦=å…¨éƒ¨ï¼‰: ").strip()
        max_imgs = int(max_imgs) if max_imgs.isdigit() else None
        test_on_images(model, test_dir, output_dir, max_images=max_imgs, min_weld_pixels=min_weld_pixels)
    
    elif choice == '5':
        # è´Ÿç‰‡æ•ˆæœå¯¹æ¯”æµ‹è¯•
        print("æ‰§è¡Œè´Ÿç‰‡æ•ˆæœå¯¹æ¯”æµ‹è¯•...")
        test_dir = input("è¯·è¾“å…¥å›¾ç‰‡ç›®å½•è·¯å¾„ï¼ˆå›è½¦ä½¿ç”¨æ ‡æ³¨/testï¼‰: ").strip()
        if not test_dir:
            test_dir = 'æ ‡æ³¨/test'
        
        if not os.path.exists(test_dir):
            print("ç›®å½•ä¸å­˜åœ¨")
            return
        
        # åˆ†åˆ«ç”¨å¯ç”¨å’Œç¦ç”¨è´Ÿç‰‡çš„æ¨¡å‹æµ‹è¯•
        output_dir = Path('negative_comparison_test')
        output_dir.mkdir(exist_ok=True)
        
        print("\n1. ä½¿ç”¨è´Ÿç‰‡é¢„å¤„ç†æµ‹è¯•...")
        model_negative = WeldSegmentationModel(encoder_name=encoder_name, use_negative=True)
        model_negative.load_model(model_path)
        results_negative = test_on_images(model_negative, test_dir, output_dir / 'with_negative', 
                                          max_images=5, min_weld_pixels=min_weld_pixels)
        
        print("\n2. ä¸ä½¿ç”¨è´Ÿç‰‡é¢„å¤„ç†æµ‹è¯•...")
        model_no_negative = WeldSegmentationModel(encoder_name=encoder_name, use_negative=False)
        model_no_negative.load_model(model_path)
        results_no_negative = test_on_images(model_no_negative, test_dir, output_dir / 'without_negative', 
                                            max_images=5, min_weld_pixels=min_weld_pixels)
        
        # å¯¹æ¯”åˆ†æ
        if results_negative and results_no_negative:
            negative_avg_ratio = np.mean([r['weld_ratio'] for r in results_negative])
            no_negative_avg_ratio = np.mean([r['weld_ratio'] for r in results_no_negative])
            negative_avg_conf = np.mean([r['avg_confidence'] for r in results_negative if r['avg_confidence'] > 0])
            no_negative_avg_conf = np.mean([r['avg_confidence'] for r in results_no_negative if r['avg_confidence'] > 0])
            
            # ç»Ÿè®¡æ£€æµ‹ç‡
            negative_detection_rate = sum(1 for r in results_negative if r.get('has_weld', True)) / len(results_negative) * 100
            no_negative_detection_rate = sum(1 for r in results_no_negative if r.get('has_weld', True)) / len(results_no_negative) * 100
            
            comparison_report = output_dir / 'negative_comparison_report.txt'
            with open(comparison_report, 'w', encoding='utf-8') as f:
                f.write("è´Ÿç‰‡æ•ˆæœå¯¹æ¯”æŠ¥å‘Š\n")
                f.write("=" * 40 + "\n")
                f.write(f"ä½¿ç”¨è´Ÿç‰‡ - å¹³å‡ç„Šç¼å æ¯”: {negative_avg_ratio:.2f}%\n")
                f.write(f"ä¸ç”¨è´Ÿç‰‡ - å¹³å‡ç„Šç¼å æ¯”: {no_negative_avg_ratio:.2f}%\n")
                f.write(f"ç„Šç¼å æ¯”å·®å¼‚: {negative_avg_ratio - no_negative_avg_ratio:.2f}%\n\n")
                f.write(f"ä½¿ç”¨è´Ÿç‰‡ - å¹³å‡ç½®ä¿¡åº¦: {negative_avg_conf:.3f}\n")
                f.write(f"ä¸ç”¨è´Ÿç‰‡ - å¹³å‡ç½®ä¿¡åº¦: {no_negative_avg_conf:.3f}\n")
                f.write(f"ç½®ä¿¡åº¦å·®å¼‚: {negative_avg_conf - no_negative_avg_conf:.3f}\n\n")
                f.write(f"ä½¿ç”¨è´Ÿç‰‡ - æ£€æµ‹æˆåŠŸç‡: {negative_detection_rate:.1f}%\n")
                f.write(f"ä¸ç”¨è´Ÿç‰‡ - æ£€æµ‹æˆåŠŸç‡: {no_negative_detection_rate:.1f}%\n")
                f.write(f"æ£€æµ‹ç‡å·®å¼‚: {negative_detection_rate - no_negative_detection_rate:.1f}%\n")
            
            print(f"\nğŸ“Š å¯¹æ¯”æµ‹è¯•å®Œæˆï¼æŠ¥å‘Šä¿å­˜åœ¨: {comparison_report}")
    
    elif choice == '6':
        # å‡ç„Šç¼è¿‡æ»¤æ•ˆæœæµ‹è¯•
        print("æ‰§è¡Œå‡ç„Šç¼è¿‡æ»¤æ•ˆæœæµ‹è¯•...")
        test_dir = input("è¯·è¾“å…¥å›¾ç‰‡ç›®å½•è·¯å¾„ï¼ˆå›è½¦ä½¿ç”¨æ ‡æ³¨/testï¼‰: ").strip()
        if not test_dir:
            test_dir = 'æ ‡æ³¨/test'
        
        if not os.path.exists(test_dir):
            print("ç›®å½•ä¸å­˜åœ¨")
            return
        
        # è·å–å›¾ç‰‡åˆ—è¡¨
        image_extensions = ['.bmp', '.jpg', '.jpeg', '.png', '.tif']
        all_images = []
        for ext in image_extensions:
            all_images.extend(list(Path(test_dir).glob(f'*{ext}')))
        
        if not all_images:
            print("ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
            return
        
        max_test = min(5, len(all_images))  # æœ€å¤šæµ‹è¯•5å¼ 
        print(f"å°†æµ‹è¯•å‰ {max_test} å¼ å›¾ç‰‡çš„è¿‡æ»¤æ•ˆæœ...")
        
        transform = get_test_transform()
        output_dir = Path('filter_test_results_negative')
        output_dir.mkdir(exist_ok=True)
        
        total_reduction = 0
        
        for i, img_path in enumerate(all_images[:max_test]):
            print(f"\n{'='*50}")
            print(f"æµ‹è¯•å›¾ç‰‡ {i+1}/{max_test}: {img_path.name}")
            print(f"{'='*50}")
            
            # åŸå§‹é¢„æµ‹
            pred_result = model.predict_single_image(img_path, transform)
            if pred_result[0] is None:
                print("è·³è¿‡ï¼ˆæ— æ³•è¯»å–ï¼‰")
                continue
            
            original_mask, confidence, enhanced_image = pred_result
            
            # åº”ç”¨è¿‡æ»¤
            filtered_mask = quick_filter_false_welds(original_mask, confidence, original_mask.shape[0])
            
            # è®¡ç®—ç»Ÿè®¡
            orig_pixels = np.sum(original_mask == 1)
            filt_pixels = np.sum(filtered_mask == 1)
            reduction = (orig_pixels - filt_pixels) / orig_pixels if orig_pixels > 0 else 0
            total_reduction += reduction
            
            print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
            print(f"  åŸå§‹ç„Šç¼åƒç´ : {orig_pixels:,}")
            print(f"  è¿‡æ»¤ååƒç´ : {filt_pixels:,}")
            print(f"  å‡å°‘æ¯”ä¾‹: {reduction*100:.1f}%")
            
            # ä¿å­˜å¯¹æ¯”ç»“æœ
            visualize_filter_comparison(img_path, original_mask, filtered_mask, confidence, enhanced_image)
            
            # å°†å¯¹æ¯”å›¾ç§»åŠ¨åˆ°ç»“æœç›®å½•
            if Path('filter_comparison.png').exists():
                new_path = output_dir / f'filter_comparison_{img_path.stem}.png'
                Path('filter_comparison.png').rename(new_path)
                print(f"  å¯¹æ¯”å›¾ä¿å­˜: {new_path}")
        
        avg_reduction = total_reduction / max_test if max_test > 0 else 0
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ:")
        print(f"  å¹³å‡å‡å°‘å‡é˜³æ€§: {avg_reduction*100:.1f}%")
        print(f"  ç»“æœä¿å­˜åœ¨: {output_dir}")
    
    elif choice == '7':
        # å•å¼ å›¾ç‰‡è¯¦ç»†è¿‡æ»¤æµ‹è¯•
        print("å•å¼ å›¾ç‰‡è¯¦ç»†è¿‡æ»¤æµ‹è¯•...")
        img_path = input("è¯·è¾“å…¥å›¾ç‰‡è·¯å¾„: ").strip()
        
        # å¤„ç†è·¯å¾„ä¸­çš„å¼•å·
        img_path = img_path.strip("'\"")
        
        if not os.path.exists(img_path):
            print(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
            print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
            return
        
        print(f"\n{'='*60}")
        print(f"è¯¦ç»†æµ‹è¯•å›¾ç‰‡: {Path(img_path).name}")
        print(f"{'='*60}")
        
        transform = get_test_transform()
        
        # åŸå§‹é¢„æµ‹
        print("1. è·å–åŸå§‹é¢„æµ‹ç»“æœ...")
        pred_result = model.predict_single_image(img_path, transform)
        if pred_result[0] is None:
            print("âŒ æ— æ³•è¯»å–å›¾ç‰‡")
            return
        
        original_mask, confidence, enhanced_image = pred_result
        orig_pixels = np.sum(original_mask == 1)
        print(f"   åŸå§‹ç„Šç¼åƒç´ : {orig_pixels:,}")
        
        # åº”ç”¨è¿‡æ»¤ï¼ˆæ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹ï¼‰
        print("\n2. åº”ç”¨å‡ç„Šç¼è¿‡æ»¤...")
        filtered_mask = quick_filter_false_welds(original_mask, confidence, original_mask.shape[0])
        filt_pixels = np.sum(filtered_mask == 1)
        
        # è®¡ç®—æ•ˆæœ
        reduction = (orig_pixels - filt_pixels) / orig_pixels if orig_pixels > 0 else 0
        print(f"\n3. è¿‡æ»¤æ•ˆæœ:")
        print(f"   è¿‡æ»¤ååƒç´ : {filt_pixels:,}")
        print(f"   å‡å°‘åƒç´ : {orig_pixels - filt_pixels:,}")
        print(f"   å‡å°‘æ¯”ä¾‹: {reduction*100:.1f}%")
        
        # ç”Ÿæˆå¯¹æ¯”å›¾
        print(f"\n4. ç”Ÿæˆå¯¹æ¯”å›¾...")
        output_dir = Path('single_filter_test_negative')
        output_dir.mkdir(exist_ok=True)
        
        visualize_filter_comparison(img_path, original_mask, filtered_mask, confidence, enhanced_image)
        
        # ç§»åŠ¨ç»“æœæ–‡ä»¶
        if Path('filter_comparison.png').exists():
            result_path = output_dir / f'filter_result_{Path(img_path).stem}.png'
            Path('filter_comparison.png').rename(result_path)
            print(f"   å¯¹æ¯”å›¾ä¿å­˜: {result_path}")
        
        print(f"\nâœ… å•å¼ å›¾ç‰‡æµ‹è¯•å®Œæˆï¼")
        if reduction > 0.1:
            print(f"ğŸ‰ æˆåŠŸè¿‡æ»¤äº† {reduction*100:.1f}% çš„å‡é˜³æ€§ï¼")
        elif reduction == 0:
            print("â„¹ï¸  æœªå‘ç°éœ€è¦è¿‡æ»¤çš„å‡ç„Šç¼")
        else:
            print("âš ï¸  å¯èƒ½éœ€è¦è°ƒæ•´è¿‡æ»¤å‚æ•°")
    
    elif choice == '8':
        # æ‰¹é‡æ£€æµ‹æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡ï¼ˆæ–°åŠŸèƒ½ï¼‰
        print("æ‰¹é‡æ£€æµ‹æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡...")
        test_dir = input("è¯·è¾“å…¥å›¾ç‰‡ç›®å½•è·¯å¾„ï¼ˆå›è½¦ä½¿ç”¨æ ‡æ³¨/testï¼‰: ").strip()
        if not test_dir:
            test_dir = 'æ ‡æ³¨/test'
        
        if not os.path.exists(test_dir):
            print("ç›®å½•ä¸å­˜åœ¨:", test_dir)
            return
        
        output_dir = f'no_weld_detection_results{"_negative" if use_negative else ""}'
        max_imgs = input("æœ€å¤§æ£€æµ‹å›¾ç‰‡æ•°é‡ï¼ˆå›è½¦=å…¨éƒ¨ï¼‰: ").strip()
        max_imgs = int(max_imgs) if max_imgs.isdigit() else None
        
        print(f"\nğŸ” å¼€å§‹æ‰¹é‡æ£€æµ‹...")
        print(f"æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼: {min_weld_pixels}")
        
        results = test_on_images(model, test_dir, output_dir, max_images=max_imgs, min_weld_pixels=min_weld_pixels)
        
        if results:
            # ç»Ÿè®¡æœªæ£€æµ‹å›¾ç‰‡
            no_weld_images = [r['image_name'] for r in results if not r.get('has_weld', True)]
            total_tested = len(results)
            no_weld_count = len(no_weld_images)
            detection_rate = (total_tested - no_weld_count) / total_tested * 100 if total_tested > 0 else 0
            
            print(f"\nğŸ“ˆ æ‰¹é‡æ£€æµ‹å®Œæˆ:")
            print(f"  æ€»æµ‹è¯•å›¾ç‰‡: {total_tested}")
            print(f"  æ£€æµ‹åˆ°ç„Šç¼: {total_tested - no_weld_count}")
            print(f"  æœªæ£€æµ‹åˆ°ç„Šç¼: {no_weld_count}")
            print(f"  æ£€æµ‹æˆåŠŸç‡: {detection_rate:.1f}%")
            
            if no_weld_images:
                print(f"\nğŸ“ æœªæ£€æµ‹åˆ°ç„Šç¼çš„å›¾ç‰‡:")
                for i, img_name in enumerate(no_weld_images[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"  {i:2d}. {img_name}")
                if len(no_weld_images) > 10:
                    print(f"  ... è¿˜æœ‰ {len(no_weld_images) - 10} å¼ å›¾ç‰‡")
                
                print(f"\nå®Œæ•´åˆ—è¡¨å·²ä¿å­˜åˆ°æ–‡æœ¬æ–‡ä»¶ä¸­ã€‚")
            else:
                print(f"\nğŸ‰ æ‰€æœ‰å›¾ç‰‡éƒ½æˆåŠŸæ£€æµ‹åˆ°ç„Šç¼ï¼")
        
    else:
        print("æ— æ•ˆé€‰æ‹©")
        return
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    if use_negative:
        print("ğŸ”„ è´Ÿç‰‡é¢„å¤„ç†: output = 255 - input")
    print(f"ğŸ—ï¸ æ¨¡å‹æ¶æ„: U-Net + {encoder_name}")
    print(f"ğŸ¯ æœ€å°ç„Šç¼åƒç´ é˜ˆå€¼: {min_weld_pixels}")

if __name__ == "__main__":
    main()