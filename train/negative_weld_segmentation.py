import os
import json
import cv2
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import segmentation_models_pytorch as smp
from sklearn.model_selection import train_test_split
import albumentations as A
from albumentations.pytorch import ToTensorV2
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
from pathlib import Path
import base64
from PIL import Image
import io
import platform

def imread_universal(file_path, flags=cv2.IMREAD_COLOR):
    """è·¨å¹³å°è¯»å–å›¾ç‰‡å‡½æ•°ï¼Œæ”¯æŒä¸åŒçš„è¯»å–æ¨¡å¼"""
    if platform.system() == "Windows":
        # Windowsä¸‹ä½¿ç”¨numpy+imdecodeæ–¹å¼
        with open(file_path, 'rb') as f:
            img_data = f.read()
        img_array = np.frombuffer(img_data, np.uint8)
        return cv2.imdecode(img_array, flags)
    else:
        # Linux/Macä¸‹ç›´æ¥ä½¿ç”¨cv2.imread
        return cv2.imread(file_path, flags)

class NegativeTransform:
    """è´Ÿç‰‡é¢„å¤„ç†ç±»"""
    
    def __init__(self, apply_probability=1.0):
        """
        åˆå§‹åŒ–è´Ÿç‰‡å˜æ¢
        Args:
            apply_probability: åº”ç”¨è´Ÿç‰‡å˜æ¢çš„æ¦‚ç‡ (0-1ä¹‹é—´)
        """
        self.apply_probability = apply_probability
    
    def apply_negative(self, image):
        """
        å¯¹å›¾åƒåº”ç”¨è´Ÿç‰‡å˜æ¢
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C) RGBæ ¼å¼ï¼Œæ•°å€¼èŒƒå›´0-255
        Returns:
            è´Ÿç‰‡å˜æ¢åçš„å›¾åƒ
        """
        # è´Ÿç‰‡å˜æ¢å…¬å¼: output = 255 - input
        negative_image = 255 - image
        return negative_image.astype(np.uint8)
    
    def __call__(self, image, mask=None):
        """
        Albumentationså…¼å®¹çš„è°ƒç”¨æ–¹å¼
        """
        # æ ¹æ®æ¦‚ç‡å†³å®šæ˜¯å¦åº”ç”¨è´Ÿç‰‡å˜æ¢
        if np.random.random() < self.apply_probability:
            image_negative = self.apply_negative(image)
        else:
            image_negative = image
        
        if mask is not None:
            return {"image": image_negative, "mask": mask}
        else:
            return {"image": image_negative}

class LabelmeDataProcessor:
    """å¤„ç†Labelmeæ ‡æ³¨æ•°æ®"""
    
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
    
    def parse_labelme_json(self, json_path):
        """è§£ælabelmeçš„JSONæ–‡ä»¶"""
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è·å–å›¾åƒä¿¡æ¯
        img_width = data['imageWidth']
        img_height = data['imageHeight']
        
        # è§£ææ ‡æ³¨ä¿¡æ¯
        shapes = data['shapes']
        polygons = []
        
        for shape in shapes:
            points = np.array(shape['points'], dtype=np.int32)
            label = shape['label']
            shape_type = shape.get('shape_type', 'polygon')
            polygons.append({
                'points': points,
                'label': label,
                'shape_type': shape_type
            })
        
        return {
            'width': img_width,
            'height': img_height,
            'polygons': polygons
        }
    
    def create_mask_from_polygons(self, polygons, img_width, img_height, class_map={'ç„Šç¼': 1}):
        """ä»å¤šè¾¹å½¢æˆ–çŸ©å½¢åˆ›å»ºåˆ†å‰²æ©ç """
        mask = np.zeros((img_height, img_width), dtype=np.uint8)
        
        for poly in polygons:
            label = poly['label']
            points = poly['points']
            shape_type = poly.get('shape_type', 'polygon')
            
            if label in class_map:
                class_id = class_map[label]
                
                if shape_type == 'rectangle':
                    # å¤„ç†çŸ©å½¢æ ‡æ³¨
                    x1, y1 = int(points[0][0]), int(points[0][1])
                    x2, y2 = int(points[1][0]), int(points[1][1])
                    cv2.rectangle(mask, (x1, y1), (x2, y2), class_id, -1)
                else:
                    # å¤„ç†å¤šè¾¹å½¢æ ‡æ³¨
                    points_int = np.array(points, dtype=np.int32)
                    cv2.fillPoly(mask, [points_int], class_id)
        
        return mask
    
    def process_dataset(self, output_dir):
        """å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
        output_path = Path(output_dir)
        images_dir = output_path / 'images'
        masks_dir = output_path / 'masks'
        
        images_dir.mkdir(parents=True, exist_ok=True)
        masks_dir.mkdir(parents=True, exist_ok=True)
        
        # æ‰¾åˆ°æ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(self.data_dir.glob('*.json'))
        
        processed_count = 0
        for json_file in json_files:
            # å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
            img_file = json_file.with_suffix('.bmp')
            
            if not img_file.exists():
                img_file = json_file.with_suffix('.png')
                if not img_file.exists():
                    print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶ {img_file}")
                    continue
            
            try:
                # è§£ææ ‡æ³¨
                annotation = self.parse_labelme_json(json_file)
                
                # è¯»å–å›¾ç‰‡
                image = imread_universal(str(img_file))
                if image is None:
                    print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾ç‰‡ {img_file}")
                    continue
                
                # åˆ›å»ºæ©ç 
                mask = self.create_mask_from_polygons(
                    annotation['polygons'],
                    annotation['width'],
                    annotation['height']
                )
                
                # ä¿å­˜å¤„ç†åçš„æ–‡ä»¶
                base_name = img_file.stem
                cv2.imwrite(str(images_dir / f'{base_name}.jpg'), image)
                cv2.imwrite(str(masks_dir / f'{base_name}.png'), mask)
                
                processed_count += 1
                
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶ {json_file} æ—¶å‡ºé”™: {e}")
        
        print(f"æˆåŠŸå¤„ç† {processed_count} ä¸ªæ–‡ä»¶")
        return processed_count

class WeldDataset(Dataset):
    """ç„Šç¼åˆ†å‰²æ•°æ®é›†"""
    
    def __init__(self, images_dir, masks_dir, transform=None, use_negative=True, negative_prob=1.0):
        self.images_dir = Path(images_dir)
        self.masks_dir = Path(masks_dir)
        self.transform = transform
        self.use_negative = use_negative
        
        # åˆå§‹åŒ–è´Ÿç‰‡å¤„ç†å™¨
        if use_negative:
            self.negative_processor = NegativeTransform(apply_probability=negative_prob)
            print(f"âœ… è´Ÿç‰‡é¢„å¤„ç†å·²å¯ç”¨ (åº”ç”¨æ¦‚ç‡={negative_prob})")
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        self.image_files = list(self.images_dir.glob('*.jpg'))
        
        # è¿‡æ»¤å‡ºæœ‰å¯¹åº”æ©ç çš„å›¾ç‰‡
        self.valid_files = []
        for img_file in self.image_files:
            mask_file = self.masks_dir / f'{img_file.stem}.png'
            if mask_file.exists():
                self.valid_files.append(img_file.stem)
        
        print(f"æ•°æ®é›†åŒ…å« {len(self.valid_files)} ä¸ªæœ‰æ•ˆæ ·æœ¬")
    
    def __len__(self):
        return len(self.valid_files)
    
    def __getitem__(self, idx):
        file_name = self.valid_files[idx]
        
        # è¯»å–å›¾ç‰‡å’Œæ©ç 
        image_path = self.images_dir / f'{file_name}.jpg'
        mask_path = self.masks_dir / f'{file_name}.png'
        
        image = imread_universal(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        mask = imread_universal(str(mask_path), cv2.IMREAD_GRAYSCALE)
        
        # åº”ç”¨è´Ÿç‰‡é¢„å¤„ç†
        if self.use_negative:
            processed = self.negative_processor(image)
            image = processed['image']
        
        # åº”ç”¨å…¶ä»–æ•°æ®å¢å¼º
        if self.transform:
            transformed = self.transform(image=image, mask=mask)
            image = transformed['image']
            mask = transformed['mask']
        
        return image, mask.long()

def get_transforms(phase='train'):
    """è·å–æ•°æ®å¢å¼ºå˜æ¢ - RTX 3080ä¼˜åŒ–ç‰ˆ"""
    if phase == 'train':
        return A.Compose([
            A.Resize(512, 512),  # 3080é™ä½åˆ°512x512ä»¥èŠ‚çœæ˜¾å­˜
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.5),
            A.RandomRotate90(p=0.5),
            A.RandomBrightnessContrast(
                brightness_limit=0.2,
                contrast_limit=0.2,
                p=0.3
            ),
            A.GaussNoise(var_limit=(10.0, 50.0), mean=0, p=0.2),
            A.OneOf([
                A.MotionBlur(blur_limit=3, p=0.2),
                A.MedianBlur(blur_limit=3, p=0.1),
                A.Blur(blur_limit=3, p=0.1),
            ], p=0.2),
            A.Affine(
                scale=(0.9, 1.1),
                translate_percent=(-0.0625, 0.0625),
                rotate=(-15, 15),
                p=0.2
            ),
            A.GridDistortion(p=0.1),
            A.ElasticTransform(p=0.1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])
    else:
        return A.Compose([
            A.Resize(512, 512),  # éªŒè¯æ—¶ä¹Ÿä½¿ç”¨512x512
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ])

def add_memory_efficient_training():
    """æ·»åŠ æ˜¾å­˜æ•ˆç‡è®­ç»ƒæŠ€å·§"""
    print("\nğŸ’¡ RTX 3080æ˜¾å­˜ä¼˜åŒ–æŠ€å·§:")
    print("1. æ··åˆç²¾åº¦è®­ç»ƒ (AMP) - èŠ‚çœ50%æ˜¾å­˜:")
    print("   from torch.cuda.amp import autocast, GradScaler")
    print("   scaler = GradScaler()")
    print("   with autocast(): outputs = model(images)")
    print()
    print("2. æ¢¯åº¦ç´¯ç§¯ - æ¨¡æ‹Ÿå¤§batchæ•ˆæœ:")
    print("   accumulation_steps = 4  # æ¨¡æ‹Ÿbatch_size=16")
    print("   if (batch_idx + 1) % accumulation_steps == 0:")
    print("       optimizer.step(); optimizer.zero_grad()")
    print()
    print("3. æ£€æŸ¥ç‚¹é‡è®¡ç®— - æ—¶é—´æ¢æ˜¾å­˜:")
    print("   model = torch.utils.checkpoint.checkpoint_sequential(model)")
    print()
    print("4. å®šæœŸæ¸…ç†æ˜¾å­˜:")
    print("   torch.cuda.empty_cache()")
    print("   del intermediate_tensors")

def get_gpu_memory_info():
    """è·å–GPUæ˜¾å­˜ä½¿ç”¨ä¿¡æ¯"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        max_allocated = torch.cuda.max_memory_allocated() / 1024**3
        
        print(f"\nğŸ” GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ:")
        print(f"  - å·²åˆ†é…: {allocated:.2f} GB")
        print(f"  - å·²ä¿ç•™: {reserved:.2f} GB") 
        print(f"  - å³°å€¼åˆ†é…: {max_allocated:.2f} GB")
        print(f"  - å‰©ä½™å¯ç”¨: {10 - reserved:.2f} GB")
        
        if reserved > 8.5:
            print("âš ï¸  æ˜¾å­˜ä½¿ç”¨æ¥è¿‘ä¸Šé™ï¼Œå»ºè®®:")
            print("  - å‡å°batch_size")
            print("  - é™ä½åˆ†è¾¨ç‡") 
            print("  - ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
    
    return allocated, reserved, max_allocated

class WeldSegmentationModel:
    """ç„Šç¼åˆ†å‰²æ¨¡å‹ - RTX 3080ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, num_classes=2, encoder_name='resnet101'):  # 3080ä½¿ç”¨æ›´è½»é‡çš„ResNet50
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆ›å»ºæ¨¡å‹ - ä½¿ç”¨U-Net with ResNet50 encoder (3080é€‚é…)
        self.model = smp.Unet(
            encoder_name=encoder_name,
            encoder_weights='imagenet',
            in_channels=3,
            classes=num_classes,
        ).to(self.device)
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ - 3080é€‚é…çš„å­¦ä¹ ç‡
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=1e-4)
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', patience=10, factor=0.5
        )
        
        print(f"æ¨¡å‹å·²åˆ›å»ºï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ‰“å°æ¨¡å‹å‚æ•°é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")
        print(f"æ˜¾å­˜ä¼˜åŒ–: ResNet50 encoder + 512x512 resolution")
    
    def dice_coefficient(self, pred, target, smooth=1e-6):
        """è®¡ç®—Diceç³»æ•°"""
        pred = torch.softmax(pred, dim=1)[:, 1]  # è·å–ç„Šç¼ç±»åˆ«çš„æ¦‚ç‡
        target = (target == 1).float()  # è½¬æ¢ä¸ºäºŒè¿›åˆ¶
        
        intersection = (pred * target).sum()
        dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
        return dice
    
    def iou_coefficient(self, pred, target, smooth=1e-6):
        """è®¡ç®—IoUç³»æ•°"""
        pred = torch.softmax(pred, dim=1)[:, 1]  # è·å–ç„Šç¼ç±»åˆ«çš„æ¦‚ç‡
        pred = (pred > 0.5).float()  # äºŒå€¼åŒ–
        target = (target == 1).float()  # è½¬æ¢ä¸ºäºŒè¿›åˆ¶
        
        intersection = (pred * target).sum()
        union = pred.sum() + target.sum() - intersection
        iou = (intersection + smooth) / (union + smooth)
        return iou
    
    def train_epoch(self, train_loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_dice = 0
        total_iou = 0
        
        for batch_idx, (images, masks) in enumerate(train_loader):
            images, masks = images.to(self.device), masks.to(self.device)
            
            self.optimizer.zero_grad()
            
            outputs = self.model(images)
            loss = self.criterion(outputs, masks)
            
            dice = self.dice_coefficient(outputs, masks)
            iou = self.iou_coefficient(outputs, masks)
            
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            total_dice += dice.item()
            total_iou += iou.item()
            
            if batch_idx % 10 == 0:  # 3080å‡å°‘è¾“å‡ºé¢‘ç‡ä»¥èŠ‚çœæ—¶é—´
                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}, Dice: {dice.item():.4f}, IoU: {iou.item():.4f}')
        
        avg_loss = total_loss / len(train_loader)
        avg_dice = total_dice / len(train_loader)
        avg_iou = total_iou / len(train_loader)
        return avg_loss, avg_dice, avg_iou
    
    def validate(self, val_loader):
        """éªŒè¯æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        total_dice = 0
        total_iou = 0
        
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(self.device), masks.to(self.device)
                
                outputs = self.model(images)
                loss = self.criterion(outputs, masks)
                dice = self.dice_coefficient(outputs, masks)
                iou = self.iou_coefficient(outputs, masks)
                
                total_loss += loss.item()
                total_dice += dice.item()
                total_iou += iou.item()
        
        avg_loss = total_loss / len(val_loader)
        avg_dice = total_dice / len(val_loader)
        avg_iou = total_iou / len(val_loader)
        return avg_loss, avg_dice, avg_iou
    
    def train(self, train_loader, val_loader, epochs=250, save_path='best_model.pth'):
        """è®­ç»ƒæ¨¡å‹ - é’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–"""
        best_dice = 0
        patience_counter = 0  # æ—©åœè®¡æ•°å™¨
        patience_limit = 30   # è¿ç»­30ä¸ªepochæ— æ”¹å–„åˆ™åœæ­¢
        
        train_losses, train_dices, train_ious = [], [], []
        val_losses, val_dices, val_ious = [], [], []
        
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒ - ä½¿ç”¨è´Ÿç‰‡é¢„å¤„ç† (RTX 3080ä¼˜åŒ–):")
        print(f"  - æ€»epochs: {epochs}")
        print(f"  - æ—©åœpatience: {patience_limit}")
        print(f"  - å½“å‰å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']}")
        print(f"  - é¢„å¤„ç†: è´Ÿç‰‡å˜æ¢ (255 - input)")
        print(f"  - æ˜¾å­˜ä¼˜åŒ–: ResNet50 + 512x512 + å°batch")
        
        for epoch in range(epochs):
            print(f'\nEpoch {epoch+1}/{epochs}')
            print('-' * 30)
            
            # è®­ç»ƒ
            train_loss, train_dice, train_iou = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss, val_dice, val_iou = self.validate(val_loader)
            
            # è®°å½•æŒ‡æ ‡
            train_losses.append(train_loss)
            train_dices.append(train_dice)
            train_ious.append(train_iou)
            val_losses.append(val_loss)
            val_dices.append(val_dice)
            val_ious.append(val_iou)
            
            print(f'Train - Loss: {train_loss:.4f}, Dice: {train_dice:.4f}, IoU: {train_iou:.4f}')
            print(f'Val   - Loss: {val_loss:.4f}, Dice: {val_dice:.4f}, IoU: {val_iou:.4f}')
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step(val_loss)
            current_lr = self.optimizer.param_groups[0]['lr']
            print(f'Learning Rate: {current_lr:.6f}')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹å’Œæ—©åœæ£€æŸ¥
            if val_dice > best_dice:
                best_dice = val_dice
                patience_counter = 0  # é‡ç½®è®¡æ•°å™¨
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'best_dice': best_dice,
                    'best_iou': val_iou,
                    'train_losses': train_losses,
                    'val_losses': val_losses,
                    'train_dices': train_dices,
                    'val_dices': val_dices,
                }, save_path)
                print(f'ğŸ‰ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒDice: {best_dice:.4f}, IoU: {val_iou:.4f}')
            else:
                patience_counter += 1
                print(f'â³ éªŒè¯Diceæœªæ”¹å–„: {patience_counter}/{patience_limit}')
            
            # æ—©åœæ£€æŸ¥
            if patience_counter >= patience_limit:
                print(f'\nğŸ›‘ æ—©åœè§¦å‘ï¼šè¿ç»­{patience_limit}ä¸ªepochéªŒè¯Diceæ— æ”¹å–„')
                print(f'æœ€ä½³Dice: {best_dice:.4f} (Epoch {epoch-patience_limit+1})')
                break
            
            # æ¯50ä¸ªepochè¾“å‡ºè®­ç»ƒè¿›åº¦æ€»ç»“
            if (epoch + 1) % 50 == 0:
                print(f'\nğŸ“Š è®­ç»ƒè¿›åº¦æ€»ç»“ (Epoch {epoch+1}):')
                print(f'  - æœ€ä½³éªŒè¯Dice: {best_dice:.4f}')
                print(f'  - å½“å‰è®­ç»ƒDice: {train_dice:.4f}')
                print(f'  - è¿‡æ‹Ÿåˆæ£€æŸ¥: {"æ­£å¸¸" if val_dice >= train_dice*0.85 else "å¯èƒ½è¿‡æ‹Ÿåˆ"}')
        
        print(f'\nâœ… è®­ç»ƒç»“æŸ! æœ€ä½³éªŒè¯Dice: {best_dice:.4f}')
        return train_losses, train_dices, val_losses, val_dices
    
    def predict(self, image, use_negative=True):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        self.model.eval()
        
        # å¦‚æœè¾“å…¥æ˜¯åŸå§‹å›¾åƒï¼Œå…ˆåº”ç”¨è´Ÿç‰‡å˜æ¢
        if use_negative and len(image.shape) == 3 and not isinstance(image, torch.Tensor):
            negative_processor = NegativeTransform(apply_probability=1.0)
            processed = negative_processor(image)
            image = processed['image']
        
        with torch.no_grad():
            if len(image.shape) == 3:
                image = image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
            
            image = image.to(self.device)
            output = self.model(image)
            pred = torch.softmax(output, dim=1)
            pred_mask = torch.argmax(pred, dim=1)
            
            return pred_mask.cpu().numpy()[0]
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        print(f"æ¨¡å‹å·²åŠ è½½ï¼Œæœ€ä½³Dice: {checkpoint['best_dice']:.4f}")

def visualize_predictions(model, dataset, num_samples=4):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
    
    for i in range(num_samples):
        # è·å–æ ·æœ¬
        image, true_mask = dataset[i]
        
        # é¢„æµ‹
        pred_mask = model.predict(image.unsqueeze(0))
        
        # è½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
        image_np = image.permute(1, 2, 0).cpu().numpy()
        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
        image_np = np.clip(image_np, 0, 1)
        
        # æ˜¾ç¤º
        axes[i, 0].imshow(image_np)
        axes[i, 0].set_title('è´Ÿç‰‡å¢å¼ºå›¾')
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(true_mask.cpu().numpy(), cmap='gray')
        axes[i, 1].set_title('çœŸå®æ©ç ')
        axes[i, 1].axis('off')
        
        axes[i, 2].imshow(pred_mask, cmap='gray')
        axes[i, 2].set_title('é¢„æµ‹æ©ç ')
        axes[i, 2].axis('off')
    
    plt.tight_layout()
    plt.show()

def compare_negative_effect(image_path, save_comparison=True):
    """æ¯”è¾ƒè´Ÿç‰‡å‰åæ•ˆæœ"""
    # è¯»å–åŸå§‹å›¾åƒ
    original = imread_universal(str(image_path))
    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
    
    # åº”ç”¨è´Ÿç‰‡å˜æ¢
    negative_processor = NegativeTransform(apply_probability=1.0)
    processed = negative_processor(original_rgb)
    negative_image = processed['image']
    
    if save_comparison:
        # å¯è§†åŒ–å¯¹æ¯”
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        
        ax1.imshow(original_rgb)
        ax1.set_title('åŸå§‹å›¾åƒ')
        ax1.axis('off')
        
        ax2.imshow(negative_image)
        ax2.set_title('è´Ÿç‰‡å˜æ¢å (255 - input)')
        ax2.axis('off')
        
        plt.tight_layout()
        plt.savefig('negative_comparison.png', dpi=150, bbox_inches='tight')
        plt.show()
        print("âœ… è´Ÿç‰‡å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º negative_comparison.png")
    
    return original_rgb, negative_image

def create_negative_demo():
    """åˆ›å»ºè´Ÿç‰‡å˜æ¢æ¼”ç¤º"""
    print("\nğŸ¯ è´Ÿç‰‡å˜æ¢åŸç†æ¼”ç¤º:")
    
    # åˆ›å»ºç¤ºä¾‹å›¾åƒ
    demo_image = np.zeros((200, 400, 3), dtype=np.uint8)
    
    # æ·»åŠ ä¸åŒäº®åº¦çš„åŒºåŸŸ
    demo_image[:, :100] = [50, 50, 50]    # æš—éƒ¨ (æ¨¡æ‹Ÿç„Šç¼)
    demo_image[:, 100:200] = [128, 128, 128]  # ä¸­ç­‰äº®åº¦
    demo_image[:, 200:300] = [200, 200, 200]  # äº®éƒ¨
    demo_image[:, 300:] = [255, 255, 255]     # æœ€äº®éƒ¨
    
    # åº”ç”¨è´Ÿç‰‡å˜æ¢
    negative_processor = NegativeTransform(apply_probability=1.0)
    processed = negative_processor(demo_image)
    negative_demo = processed['image']
    
    # æ˜¾ç¤ºå¯¹æ¯”
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    ax1.imshow(demo_image)
    ax1.set_title('åŸå§‹å›¾åƒ\n(å·¦ä¾§æ¨¡æ‹Ÿæš—éƒ¨ç„Šç¼)')
    ax1.axis('off')
    
    ax2.imshow(negative_demo)
    ax2.set_title('è´Ÿç‰‡å˜æ¢å\n(æš—éƒ¨ç„Šç¼å˜äº®ï¼Œæ›´æ˜“æ£€æµ‹)')
    ax2.axis('off')
    
    plt.tight_layout()
    plt.savefig('negative_principle_demo.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print("âœ… è´Ÿç‰‡å˜æ¢åŸç†æ¼”ç¤ºå›¾å·²ä¿å­˜ä¸º negative_principle_demo.png")
    print("ğŸ’¡ å…³é”®ä¼˜åŠ¿:")
    print("  - æš—éƒ¨ç„Šç¼ â†’ äº®éƒ¨ç‰¹å¾ï¼Œæé«˜å¯è§æ€§")
    print("  - å¢å¼ºç„Šç¼ä¸èƒŒæ™¯çš„å¯¹æ¯”åº¦")
    print("  - ç®€å•é«˜æ•ˆï¼Œæ— éœ€å¤æ‚å‚æ•°è°ƒä¼˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ç„Šç¼åŒºåŸŸç²¾ç¡®åˆ†å‰²ç³»ç»Ÿ - RTX 3080ä¼˜åŒ–ç‰ˆ + è´Ÿç‰‡å¢å¼º")
    print("=" * 60)
    
    # GPUæ˜¾å­˜ä¼˜åŒ–è®¾ç½®
    if torch.cuda.is_available():
        print(f"æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name()}")
        print(f"æ˜¾å­˜å®¹é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # è®¾ç½®æ˜¾å­˜ä¼˜åŒ–é€‰é¡¹
        torch.backends.cudnn.benchmark = True  # ä¼˜åŒ–å·ç§¯æ€§èƒ½
        torch.cuda.empty_cache()  # æ¸…ç©ºæ˜¾å­˜ç¼“å­˜
        
        # è®¾ç½®PyTorchæ˜¾å­˜åˆ†é…ç­–ç•¥
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
        print("âœ… æ˜¾å­˜ä¼˜åŒ–è®¾ç½®å·²å¯ç”¨")
    
    # 1. å¤„ç†è®­ç»ƒæ•°æ® (trainç›®å½• - æœ‰æ ‡æ³¨)
    print("\n1. å¤„ç†è®­ç»ƒæ•°æ®...")
    train_processor = LabelmeDataProcessor('æ ‡æ³¨/train')
    train_count = train_processor.process_dataset('processed_data/train')
    print(f"è®­ç»ƒæ•°æ®å¤„ç†å®Œæˆ: {train_count} ä¸ªæ ·æœ¬")
    
    if train_count == 0:
        print("é”™è¯¯: è®­ç»ƒé›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•")
        return
    
    # 2. æ£€æŸ¥testç›®å½•æƒ…å†µ
    test_dir = Path('æ ‡æ³¨/test')
    test_bmps = list(test_dir.glob('*.bmp')) if test_dir.exists() else []
    test_jsons = list(test_dir.glob('*.json')) if test_dir.exists() else []
    
    print(f"\n2. æ£€æŸ¥éªŒè¯æ•°æ®...")
    print(f"testç›®å½•å›¾ç‰‡æ•°: {len(test_bmps)}")
    print(f"testç›®å½•æ ‡æ³¨æ•°: {len(test_jsons)}")
    
    if len(test_jsons) == 0 and len(test_bmps) > 0:
        print("è­¦å‘Š: testç›®å½•åªæœ‰å›¾ç‰‡æ²¡æœ‰æ ‡æ³¨ï¼Œå°†ä»trainæ•°æ®ä¸­åˆ’åˆ†éªŒè¯é›†")
        use_train_split = True
    elif len(test_jsons) > 0:
        print("âœ… testç›®å½•æœ‰æ ‡æ³¨ï¼Œå°†ä½œä¸ºéªŒè¯é›†")
        use_train_split = False
        # å¤„ç†testç›®å½•çš„æ ‡æ³¨æ•°æ®
        test_processor = LabelmeDataProcessor('æ ‡æ³¨/test')  
        val_count = test_processor.process_dataset('processed_data/val')
        print(f"éªŒè¯æ•°æ®å¤„ç†å®Œæˆ: {val_count} ä¸ªæ ·æœ¬")
    else:
        print("ä»trainæ•°æ®ä¸­åˆ’åˆ†éªŒè¯é›†")
        use_train_split = True
    
    # 3. æ¼”ç¤ºè´Ÿç‰‡æ•ˆæœ
    print(f"\n3. è´Ÿç‰‡é¢„å¤„ç†æ¼”ç¤º...")
    train_images = list(Path('processed_data/train/images').glob('*.jpg'))
    if len(train_images) > 0:
        print(f"ä½¿ç”¨ {train_images[0].name} å±•ç¤ºè´Ÿç‰‡æ•ˆæœ")
        compare_negative_effect(train_images[0])
    
    # 4. åˆ›å»ºæ•°æ®é›† - å¯ç”¨è´Ÿç‰‡é¢„å¤„ç†
    print(f"\n4. åˆ›å»ºæ•°æ®é›†ï¼ˆå¯ç”¨è´Ÿç‰‡é¢„å¤„ç†ï¼‰...")
    
    if use_train_split:
        # ä»trainæ•°æ®ä¸­åˆ’åˆ†
        print("ä»è®­ç»ƒæ•°æ®ä¸­åˆ’åˆ†80%è®­ç»ƒï¼Œ20%éªŒè¯")
        full_dataset = WeldDataset(
            'processed_data/train/images',
            'processed_data/train/masks',
            transform=get_transforms('train'),
            use_negative=True,  # å¯ç”¨è´Ÿç‰‡å˜æ¢
            negative_prob=1.0   # 100%åº”ç”¨è´Ÿç‰‡å˜æ¢
        )
        
        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        train_size = int(0.8 * len(full_dataset))
        val_size = len(full_dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(
            full_dataset, [train_size, val_size],
            generator=torch.Generator().manual_seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯å¯å¤ç°
        )
        
        # ä¸ºéªŒè¯é›†åˆ›å»ºå•ç‹¬çš„æ•°æ®é›†å®ä¾‹
        val_dataset_instance = WeldDataset(
            'processed_data/train/images',
            'processed_data/train/masks',
            transform=get_transforms('val'),
            use_negative=True,  # éªŒè¯é›†ä¹Ÿå¯ç”¨è´Ÿç‰‡å˜æ¢
            negative_prob=1.0   # éªŒè¯æ—¶ä¹Ÿ100%åº”ç”¨
        )
        
        # è·å–éªŒè¯é›†çš„ç´¢å¼•
        val_indices = val_dataset.indices
        val_dataset_instance.valid_files = [full_dataset.valid_files[i] for i in val_indices]
        val_dataset = val_dataset_instance
        
    else:
        # ä½¿ç”¨ç‹¬ç«‹çš„éªŒè¯é›†
        print("ä½¿ç”¨ç‹¬ç«‹çš„éªŒè¯é›†")
        train_dataset = WeldDataset(
            'processed_data/train/images',
            'processed_data/train/masks',
            transform=get_transforms('train'),
            use_negative=True,  # å¯ç”¨è´Ÿç‰‡å˜æ¢
            negative_prob=1.0
        )
        
        val_dataset = WeldDataset(
            'processed_data/val/images',
            'processed_data/val/masks',
            transform=get_transforms('val'),
            use_negative=True,  # å¯ç”¨è´Ÿç‰‡å˜æ¢
            negative_prob=1.0
        )
    
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(val_dataset)}")
    
    # RTX 3080 10GBæ˜¾å­˜ä¼˜åŒ–çš„batch sizeå’Œworkerè®¾ç½®
    batch_size = 4  # 3080 10GBä½¿ç”¨å°batch size
    num_workers = 4  # å‡å°‘workeræ•°é‡
    
    print(f"\nğŸ”§ RTX 3080æ˜¾å­˜ä¼˜åŒ–é…ç½®:")
    print(f"  - Batch Size: {batch_size} (æ˜¾å­˜ä¼˜åŒ–)")
    print(f"  - Workers: {num_workers}")
    print(f"  - å›¾ç‰‡åˆ†è¾¨ç‡: 512x512")
    print(f"  - æ¨¡å‹: U-Net + ResNet50")
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True,  # ä¿æŒpin_memoryä»¥æå‡æ€§èƒ½
        persistent_workers=True  # ä¿æŒworkerè¿›ç¨‹ï¼Œå‡å°‘é‡å¤å¯åŠ¨å¼€é”€
    )
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=True
    )
    
    # 5. åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
    print(f"\n5. åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹...")
    print(f"é¢„å¤„ç†: è´Ÿç‰‡å˜æ¢ (255 - input)")
    
    model = WeldSegmentationModel(num_classes=2, encoder_name='resnet50')  # ä½¿ç”¨ResNet50
    
    # è®­ç»ƒæ¨¡å‹ - é’ˆå¯¹230å¼ å›¾åƒä¼˜åŒ–çš„è®­ç»ƒç­–ç•¥
    print("ğŸ”§ è®­ç»ƒç­–ç•¥ (RTX 3080ä¼˜åŒ–):")
    print(f"  - æ•°æ®é›†å¤§å°: ~230å¼ å›¾åƒ")
    print(f"  - æ¨èepochs: 200-250")
    print(f"  - æ—©åœæœºåˆ¶: éªŒè¯Diceè¿ç»­30ä¸ªepochä¸æå‡æ—¶åœæ­¢")
    print(f"  - å­¦ä¹ ç‡è°ƒåº¦: éªŒè¯æŸå¤±10ä¸ªepochä¸ä¸‹é™æ—¶å‡åŠ")
    print(f"  - è´Ÿç‰‡å˜æ¢: 100%åº”ç”¨æ¦‚ç‡ï¼Œåè½¬æ˜æš—å¯¹æ¯”")
    print(f"  - æ˜¾å­˜ä¼˜åŒ–: å°batch + è½»é‡æ¨¡å‹ + ä½åˆ†è¾¨ç‡")
    
    train_losses, train_dices, val_losses, val_dices = model.train(
        train_loader, val_loader, epochs=500, save_path='best_weld_model_negative_3080.pth'
    )
    
    # 6. å¯è§†åŒ–ç»“æœ
    print("\n6. å¯è§†åŒ–é¢„æµ‹ç»“æœ...")
    model.load_model('best_weld_model_negative_3080.pth')
    
    visualize_predictions(model, val_dataset, num_samples=4)  # 3080å‡å°‘æ ·ä¾‹æ•°é‡
    
    print(f"\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º: best_weld_model_negative_3080.pth")
    print(f"è®­ç»ƒé›†æ ·æœ¬: {len(train_dataset)}")
    print(f"éªŒè¯é›†æ ·æœ¬: {len(val_dataset)}")
    print(f"è´Ÿç‰‡é¢„å¤„ç†: 100%åº”ç”¨ï¼Œå…¬å¼ä¸º output = 255 - input")
    print(f"RTX 3080ä¼˜åŒ–: ResNet50 + 512px + batch_size=4")
    
    # 7. å¦‚æœtestç›®å½•æœ‰æœªæ ‡æ³¨å›¾ç‰‡ï¼Œæä¾›é¢„æµ‹åŠŸèƒ½
    if len(test_bmps) > 0 and len(test_jsons) == 0:
        print(f"\n7. testç›®å½•æœ‰ {len(test_bmps)} å¼ æœªæ ‡æ³¨å›¾ç‰‡")
        print("å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹")
        
        # åˆ›å»ºé¢„æµ‹å‡½æ•°
        def predict_test_images():
            print("å¼€å§‹é¢„æµ‹testç›®å½•å›¾ç‰‡...")
            test_output_dir = Path('test_predictions_negative_3080')
            test_output_dir.mkdir(exist_ok=True)
            
            transform = get_transforms('val')
            negative_processor = NegativeTransform(apply_probability=1.0)
            
            # æ‰¹é‡é¢„æµ‹ä»¥èŠ‚çœæ—¶é—´
            for i, img_path in enumerate(test_bmps[:10]):  # é¢„æµ‹å‰10å¼ ä½œä¸ºç¤ºä¾‹
                # è¯»å–å›¾ç‰‡
                image = imread_universal(str(img_path))
                if image is None:
                    continue
                    
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # åº”ç”¨è´Ÿç‰‡é¢„å¤„ç†
                processed = negative_processor(image_rgb)
                image_negative = processed['image']
                
                # å…¶ä»–é¢„å¤„ç†
                transformed = transform(image=image_negative)
                input_tensor = transformed['image'].unsqueeze(0)
                
                # é¢„æµ‹
                pred_mask = model.predict(input_tensor, use_negative=False)  # å·²ç»åº”ç”¨äº†è´Ÿç‰‡å˜æ¢
                
                # ä¿å­˜ç»“æœ
                output_path = test_output_dir / f'pred_{img_path.stem}.png'
                cv2.imwrite(str(output_path), pred_mask * 255)
                
                # åŒæ—¶ä¿å­˜è´Ÿç‰‡å¤„ç†åçš„å›¾ç‰‡ç”¨äºå¯¹æ¯”
                negative_img_path = test_output_dir / f'negative_{img_path.stem}.jpg'
                cv2.imwrite(str(negative_img_path), cv2.cvtColor(image_negative, cv2.COLOR_RGB2BGR))
                
                if i < 3:  # æ˜¾ç¤ºå‰3ä¸ªé¢„æµ‹ç»“æœçš„ä¿¡æ¯
                    weld_pixels = np.sum(pred_mask > 0)
                    total_pixels = pred_mask.shape[0] * pred_mask.shape[1]
                    print(f"  {img_path.name}: ç„Šç¼å æ¯” {weld_pixels/total_pixels*100:.2f}%")
                
                # æ¸…ç†æ˜¾å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            
            print(f"é¢„æµ‹å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {test_output_dir}")
            print("åŒ…å«: é¢„æµ‹æ©ç  (pred_*.png) å’Œ è´Ÿç‰‡å¢å¼ºå›¾ (negative_*.jpg)")
        
        # è¯¢é—®æ˜¯å¦è¿›è¡Œé¢„æµ‹
        print("æ˜¯å¦å¯¹testå›¾ç‰‡è¿›è¡Œé¢„æµ‹ï¼Ÿè¾“å…¥ 'y' ç¡®è®¤ï¼š")
        # predict_test_images()  # å¯ä»¥å–æ¶ˆæ³¨é‡Šè‡ªåŠ¨é¢„æµ‹
        
    print("=" * 60)
    print("ğŸ“ RTX 3080ä¼˜åŒ–æ€»ç»“:")
    print("  - åˆ†è¾¨ç‡: 640x640 â†’ 512x512 (èŠ‚çœæ˜¾å­˜)")
    print("  - æ¨¡å‹: ResNet101 â†’ ResNet50 (å‡å°‘å‚æ•°)")
    print("  - Batch Size: 12 â†’ 4 (é€‚é…10GBæ˜¾å­˜)")
    print("  - Workers: 8 â†’ 4 (å‡å°‘å†…å­˜å ç”¨)")
    print("  - å­¦ä¹ ç‡: 2e-4 â†’ 1e-4 (æ›´ç¨³å®š)")
    print("  - Patience: 8 â†’ 10 (æ›´å®½å®¹çš„è°ƒåº¦)")
    print("  - è´Ÿç‰‡å˜æ¢: output = 255 - input")
    print("  - æ˜¾å­˜ç®¡ç†: expandable_segments + empty_cache")

if __name__ == "__main__":
    # æ˜¾ç¤ºæ˜¾å­˜ä¼˜åŒ–æŠ€å·§
    add_memory_efficient_training()
    
    # é¦–å…ˆæ¼”ç¤ºè´Ÿç‰‡å˜æ¢åŸç†
    create_negative_demo()
    
    # è¿è¡Œä¸»ç¨‹åºå‰æ£€æŸ¥æ˜¾å­˜
    if torch.cuda.is_available():
        get_gpu_memory_info()
    
    # è¿è¡Œä¸»ç¨‹åº
    main()
    
    # è®­ç»ƒå®Œæˆåå†æ¬¡æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨
    if torch.cuda.is_available():
        print("\nè®­ç»ƒå®Œæˆåçš„æ˜¾å­˜çŠ¶æ€:")
        get_gpu_memory_info()