"""
è„šæœ¬åç§°: yolo_roi_extractor.py
åŠŸèƒ½æ¦‚è¿°: ä½¿ç”¨YOLOæ¨¡å‹ä»æ•°æ®é›†ä¸­æå–ROIåŒºåŸŸå¹¶é‡æ–°è®¡ç®—æ ‡ç­¾
è¯¦ç»†è¯´æ˜:
    - è¾“å…¥æ ¼å¼: YOLOæ ¼å¼æ•°æ®é›† + YOLOæ¨¡å‹æƒé‡
    - å¤„ç†æµç¨‹: æ¨¡å‹æ¨ç† â†’ ROIæ£€æµ‹ â†’ å›¾åƒè£å‰ª â†’ æ ‡ç­¾é‡è®¡ç®—
    - è¾“å‡ºæ ¼å¼: ä»…åŒ…å«ROIåŒºåŸŸçš„YOLOæ•°æ®é›†
ä¾èµ–æ¨¡å—: utils.label_processing, utils.dataset_management, ultralytics
ä½¿ç”¨ç¤ºä¾‹:
    # åŸºæœ¬ä½¿ç”¨ï¼ˆæ£€æµ‹æ¨¡å¼ï¼‰
    python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt

    # åˆ†å‰²æ¨¡å¼
    python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --mode seg

    # è°ƒæ•´ROIæ£€æµ‹é˜ˆå€¼
    python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --roi_conf 0.5

    # å¢åŠ ROIåŒºåŸŸpadding
    python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --padding 0.2
"""

import os
import sys
import cv2
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional
from tqdm import tqdm
from ultralytics import YOLO

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils import (
    read_yolo_labels,
    save_yolo_labels,
    denormalize_bbox,
    normalize_bbox,
    clip_polygon_to_window,
    create_directory_structure,
    read_dataset_yaml,
    update_dataset_yaml
)


class YOLOROIExtractor:
    """YOLO ROIåŒºåŸŸæå–å™¨"""

    def __init__(self,
                 input_dir: str,
                 output_dir: str,
                 model_path: str,
                 mode: str = 'det',
                 roi_conf_threshold: float = 0.25,
                 roi_iou_threshold: float = 0.45,
                 padding_ratio: float = 0.1):
        """
        åˆå§‹åŒ–ROIæå–å™¨

        Args:
            input_dir: è¾“å…¥YOLOæ•°æ®é›†ç›®å½•
            output_dir: è¾“å‡ºYOLOæ•°æ®é›†ç›®å½•
            model_path: YOLOæ¨¡å‹æƒé‡è·¯å¾„
            mode: 'det'(æ£€æµ‹) æˆ– 'seg'(åˆ†å‰²)
            roi_conf_threshold: ROIæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            roi_iou_threshold: ROIæ£€æµ‹IOUé˜ˆå€¼
            padding_ratio: ROIåŒºåŸŸpaddingæ¯”ä¾‹
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.model_path = model_path
        self.mode = mode
        self.roi_conf_threshold = roi_conf_threshold
        self.roi_iou_threshold = roi_iou_threshold
        self.padding_ratio = padding_ratio

        # åŠ è½½YOLOæ¨¡å‹
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        self.model = YOLO(model_path)

        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        create_directory_structure(self.output_dir)

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_processed = 0
        self.total_roi_found = 0
        self.total_labels_adjusted = 0

        print(f"YOLO ROIæå–å™¨åˆå§‹åŒ–:")
        print(f"  - è¾“å…¥ç›®å½•: {input_dir}")
        print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
        print(f"  - æ¨¡å¼: {mode}")
        print(f"  - ROIç½®ä¿¡åº¦é˜ˆå€¼: {roi_conf_threshold}")
        print(f"  - ROI IOUé˜ˆå€¼: {roi_iou_threshold}")
        print(f"  - Paddingæ¯”ä¾‹: {padding_ratio}")

    def _detect_roi(self, image_path: str) -> List[Tuple[int, int, int, int]]:
        """
        ä½¿ç”¨YOLOæ¨¡å‹æ£€æµ‹ROIåŒºåŸŸ

        Args:
            image_path: å›¾åƒè·¯å¾„

        Returns:
            ROIè¾¹ç•Œæ¡†åˆ—è¡¨ [(x1, y1, x2, y2), ...]
        """
        results = self.model(
            image_path,
            conf=self.roi_conf_threshold,
            iou=self.roi_iou_threshold,
            verbose=False
        )

        roi_boxes = []
        for result in results:
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                for box in boxes:
                    x1, y1, x2, y2 = box
                    roi_boxes.append((int(x1), int(y1), int(x2), int(y2)))

        return roi_boxes

    def _add_padding(self, x1: int, y1: int, x2: int, y2: int,
                    img_width: int, img_height: int) -> Tuple[int, int, int, int]:
        """
        ä¸ºROIåŒºåŸŸæ·»åŠ padding

        Args:
            x1, y1, x2, y2: ROIè¾¹ç•Œæ¡†
            img_width, img_height: å›¾åƒå°ºå¯¸

        Returns:
            æ·»åŠ paddingåçš„è¾¹ç•Œæ¡†
        """
        width = x2 - x1
        height = y2 - y1

        # è®¡ç®—padding
        pad_x = int(width * self.padding_ratio)
        pad_y = int(height * self.padding_ratio)

        # æ·»åŠ paddingå¹¶ç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
        x1_padded = max(0, x1 - pad_x)
        y1_padded = max(0, y1 - pad_y)
        x2_padded = min(img_width, x2 + pad_x)
        y2_padded = min(img_height, y2 + pad_y)

        return x1_padded, y1_padded, x2_padded, y2_padded

    def _process_detection_label(self, label: list, roi_x1: int, roi_y1: int,
                                roi_x2: int, roi_y2: int,
                                img_width: int, img_height: int,
                                cropped_width: int, cropped_height: int) -> Optional[list]:
        """
        å¤„ç†æ£€æµ‹æ¨¡å¼çš„æ ‡ç­¾

        Args:
            label: [class_id, x_center, y_center, width, height]
            roi_*: ROIåŒºåŸŸåƒç´ åæ ‡
            img_*: åŸå§‹å›¾åƒå°ºå¯¸
            cropped_*: è£å‰ªåå›¾åƒå°ºå¯¸

        Returns:
            è°ƒæ•´åçš„æ ‡ç­¾æˆ–None
        """
        class_id = int(label[0])

        # è½¬æ¢ä¸ºåƒç´ åæ ‡
        x1, y1, x2, y2 = denormalize_bbox(
            label[1], label[2], label[3], label[4],
            img_width, img_height
        )

        # è®¡ç®—ä¸ROIçš„äº¤é›†
        intersect_x1 = max(x1, roi_x1)
        intersect_y1 = max(y1, roi_y1)
        intersect_x2 = min(x2, roi_x2)
        intersect_y2 = min(y2, roi_y2)

        # å¦‚æœæ²¡æœ‰äº¤é›†
        if intersect_x1 >= intersect_x2 or intersect_y1 >= intersect_y2:
            return None

        # è½¬æ¢ä¸ºç›¸å¯¹äºè£å‰ªå›¾åƒçš„åæ ‡
        new_x1 = max(0, intersect_x1 - roi_x1)
        new_y1 = max(0, intersect_y1 - roi_y1)
        new_x2 = min(cropped_width, intersect_x2 - roi_x1)
        new_y2 = min(cropped_height, intersect_y2 - roi_y1)

        # è½¬æ¢å›å½’ä¸€åŒ–åæ ‡
        new_x_center, new_y_center, new_width, new_height = normalize_bbox(
            new_x1, new_y1, new_x2, new_y2, cropped_width, cropped_height
        )

        # è¿‡æ»¤å¤ªå°çš„è¾¹ç•Œæ¡†
        if new_width <= 0.01 or new_height <= 0.01:
            return None

        return [class_id, new_x_center, new_y_center, new_width, new_height]

    def _process_segmentation_label(self, label: list, roi_x1: int, roi_y1: int,
                                   roi_x2: int, roi_y2: int,
                                   img_width: int, img_height: int,
                                   cropped_width: int, cropped_height: int) -> Optional[list]:
        """
        å¤„ç†åˆ†å‰²æ¨¡å¼çš„æ ‡ç­¾

        Args:
            label: [class_id, x1, y1, x2, y2, ...]
            roi_*: ROIåŒºåŸŸåƒç´ åæ ‡
            img_*: åŸå§‹å›¾åƒå°ºå¯¸
            cropped_*: è£å‰ªåå›¾åƒå°ºå¯¸

        Returns:
            è°ƒæ•´åçš„æ ‡ç­¾æˆ–None
        """
        class_id = int(label[0])
        points = label[1:]

        # è½¬æ¢ä¸ºåƒç´ åæ ‡å¹¶è°ƒæ•´åˆ°ROIåŒºåŸŸ
        new_points = []
        for i in range(0, len(points), 2):
            if i + 1 < len(points):
                x = points[i] * img_width
                y = points[i + 1] * img_height

                # è°ƒæ•´åˆ°ROIåŒºåŸŸåæ ‡ç³»
                x_adjusted = x - roi_x1
                y_adjusted = y - roi_y1

                # å½’ä¸€åŒ–åˆ°è£å‰ªå›¾åƒ
                new_x = x_adjusted / cropped_width
                new_y = y_adjusted / cropped_height

                new_points.extend([new_x, new_y])

        # è£å‰ªå¤šè¾¹å½¢åˆ°çª—å£å†…
        clipped_points = clip_polygon_to_window(new_points, (0.0, 0.0, 1.0, 1.0))

        # æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆ
        if len(clipped_points) < 6:  # è‡³å°‘3ä¸ªç‚¹
            return None

        # è®¡ç®—å¤šè¾¹å½¢é¢ç§¯ï¼Œè¿‡æ»¤å¤ªå°çš„
        x_coords = clipped_points[::2]
        y_coords = clipped_points[1::2]

        if not x_coords or not y_coords:
            return None

        poly_width = max(x_coords) - min(x_coords)
        poly_height = max(y_coords) - min(y_coords)

        if poly_width <= 0.01 or poly_height <= 0.01:
            return None

        return [class_id] + clipped_points

    def _process_single_image(self, image_path: Path, label_path: Path,
                            split_type: str):
        """
        å¤„ç†å•å¼ å›¾åƒ

        Args:
            image_path: å›¾åƒè·¯å¾„
            label_path: æ ‡ç­¾è·¯å¾„
            split_type: 'train' æˆ– 'val'
        """
        # è¯»å–å›¾åƒ
        img = cv2.imread(str(image_path))
        if img is None:
            print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_path}")
            return

        img_height, img_width = img.shape[:2]

        # æ£€æµ‹ROIåŒºåŸŸ
        roi_boxes = self._detect_roi(str(image_path))

        if not roi_boxes:
            print(f"è­¦å‘Š: æœªæ£€æµ‹åˆ°ROI {image_path}")
            return

        self.total_roi_found += len(roi_boxes)

        # è¯»å–åŸå§‹æ ‡ç­¾
        original_labels = read_yolo_labels(str(label_path), self.mode)

        # å¤„ç†æ¯ä¸ªROIåŒºåŸŸ
        base_name = image_path.stem
        for roi_idx, (roi_x1, roi_y1, roi_x2, roi_y2) in enumerate(roi_boxes):
            # æ·»åŠ padding
            roi_x1, roi_y1, roi_x2, roi_y2 = self._add_padding(
                roi_x1, roi_y1, roi_x2, roi_y2, img_width, img_height
            )

            # è£å‰ªå›¾åƒ
            cropped_img = img[roi_y1:roi_y2, roi_x1:roi_x2]
            cropped_height, cropped_width = cropped_img.shape[:2]

            # ç”Ÿæˆæ–°æ–‡ä»¶å
            new_img_name = f"{base_name}_roi_{roi_idx}.jpg"
            new_label_name = f"{base_name}_roi_{roi_idx}.txt"

            # ä¿å­˜è£å‰ªåçš„å›¾åƒ
            output_img_path = self.output_dir / 'images' / split_type / new_img_name
            cv2.imwrite(str(output_img_path), cropped_img,
                       [cv2.IMWRITE_JPEG_QUALITY, 95])

            # å¤„ç†æ ‡ç­¾
            new_labels = []
            for label in original_labels:
                if self.mode == 'det':
                    new_label = self._process_detection_label(
                        label, roi_x1, roi_y1, roi_x2, roi_y2,
                        img_width, img_height, cropped_width, cropped_height
                    )
                else:  # seg mode
                    new_label = self._process_segmentation_label(
                        label, roi_x1, roi_y1, roi_x2, roi_y2,
                        img_width, img_height, cropped_width, cropped_height
                    )

                if new_label is not None:
                    new_labels.append(new_label)
                    self.total_labels_adjusted += 1

            # ä¿å­˜æ–°çš„æ ‡ç­¾æ–‡ä»¶
            output_label_path = self.output_dir / 'labels' / split_type / new_label_name
            save_yolo_labels(new_labels, str(output_label_path), self.mode)

        self.total_processed += 1

    def process_dataset(self):
        """å¤„ç†æ•´ä¸ªæ•°æ®é›†"""
        print(f"å¼€å§‹å¤„ç†æ•°æ®é›†...")

        # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        for split_type in ['train', 'val']:
            image_dir = self.input_dir / 'images' / split_type
            label_dir = self.input_dir / 'labels' / split_type

            if not image_dir.exists():
                print(f"è·³è¿‡{split_type}ï¼ˆä¸å­˜åœ¨ï¼‰")
                continue

            # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_files = list(image_dir.glob('*.jpg')) + \
                         list(image_dir.glob('*.jpeg')) + \
                         list(image_dir.glob('*.png')) + \
                         list(image_dir.glob('*.bmp'))

            print(f"\nå¤„ç†{split_type}é›†: {len(image_files)}å¼ å›¾åƒ")

            # å¤„ç†æ¯å¼ å›¾åƒ
            for image_path in tqdm(image_files, desc=f"å¤„ç†{split_type}"):
                # æ„é€ å¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„
                label_path = label_dir / f"{image_path.stem}.txt"

                # å³ä½¿æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿå¤„ç†
                if not label_path.exists():
                    # åˆ›å»ºç©ºæ ‡ç­¾æ–‡ä»¶
                    label_path = Path("/dev/null")

                self._process_single_image(image_path, label_path, split_type)

        # å¤åˆ¶å¹¶æ›´æ–°dataset.yaml
        self._update_dataset_yaml()

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self._print_statistics()

    def _update_dataset_yaml(self):
        """æ›´æ–°dataset.yamlæ–‡ä»¶"""
        input_yaml = self.input_dir / 'dataset.yaml'
        output_yaml = self.output_dir / 'dataset.yaml'

        if input_yaml.exists():
            yaml_data = read_dataset_yaml(str(input_yaml))

            # æ›´æ–°è·¯å¾„
            yaml_data['train'] = str(self.output_dir / 'images' / 'train')
            yaml_data['val'] = str(self.output_dir / 'images' / 'val')

            # æ·»åŠ ROIæå–ä¿¡æ¯
            yaml_data['roi_extraction'] = {
                'model_path': str(self.model_path),
                'conf_threshold': self.roi_conf_threshold,
                'iou_threshold': self.roi_iou_threshold,
                'padding_ratio': self.padding_ratio
            }

            # ä¿å­˜æ›´æ–°åçš„yaml
            update_dataset_yaml(str(output_yaml), yaml_data)

            print(f"dataset.yamlå·²ä¿å­˜åˆ°: {output_yaml}")
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°{input_yaml}")

    def _print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*60}")
        print(f"âœ… ROIæå–å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - å¤„ç†å›¾åƒæ•°: {self.total_processed}")
        print(f"  - æ£€æµ‹åˆ°çš„ROIæ•°: {self.total_roi_found}")
        print(f"  - è°ƒæ•´çš„æ ‡ç­¾æ•°: {self.total_labels_adjusted}")
        print(f"  - å¹³å‡æ¯å¼ å›¾åƒROIæ•°: {self.total_roi_found/max(1, self.total_processed):.2f}")
        print(f"  - è¾“å‡ºç›®å½•: {self.output_dir}")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨YOLOæ¨¡å‹ä»æ•°æ®é›†ä¸­æå–ROIåŒºåŸŸ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨ï¼ˆæ£€æµ‹æ¨¡å¼ï¼‰
  python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt
  
  # åˆ†å‰²æ¨¡å¼
  python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --mode seg
  
  # è°ƒæ•´ROIæ£€æµ‹é˜ˆå€¼
  python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --roi_conf 0.5 --roi_iou 0.7
  
  # å¢åŠ ROIåŒºåŸŸpaddingï¼ˆ20%ï¼‰
  python yolo_roi_extractor.py --input_dir ./dataset --output_dir ./roi_dataset --model_path ./weights/best.pt --padding 0.2
        """
    )

    parser.add_argument('--input_dir', type=str, required=True,
                       help='è¾“å…¥YOLOæ•°æ®é›†ç›®å½•')
    parser.add_argument('--output_dir', type=str, required=True,
                       help='è¾“å‡ºROIæ•°æ®é›†ç›®å½•')
    parser.add_argument('--model_path', type=str, required=True,
                       help='YOLOæ¨¡å‹æƒé‡è·¯å¾„ï¼ˆ.ptæ–‡ä»¶ï¼‰')
    parser.add_argument('--mode', type=str, choices=['det', 'seg'], default='det',
                       help='æ•°æ®é›†æ¨¡å¼: det(æ£€æµ‹) æˆ– seg(åˆ†å‰²) (é»˜è®¤: det)')
    parser.add_argument('--roi_conf', type=float, default=0.25,
                       help='ROIæ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤: 0.25)')
    parser.add_argument('--roi_iou', type=float, default=0.45,
                       help='ROIæ£€æµ‹IOUé˜ˆå€¼ (é»˜è®¤: 0.45)')
    parser.add_argument('--padding', type=float, default=0.1,
                       help='ROIåŒºåŸŸpaddingæ¯”ä¾‹ (é»˜è®¤: 0.1)')

    args = parser.parse_args()

    # åˆ›å»ºROIæå–å™¨
    extractor = YOLOROIExtractor(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        model_path=args.model_path,
        mode=args.mode,
        roi_conf_threshold=args.roi_conf,
        roi_iou_threshold=args.roi_iou,
        padding_ratio=args.padding
    )

    # å¤„ç†æ•°æ®é›†
    extractor.process_dataset()


if __name__ == '__main__':
    main()